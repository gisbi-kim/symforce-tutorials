{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f90f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "symforce uses symengine as backend\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import copy \n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "import open3d as o3d\n",
    "\n",
    "import symforce \n",
    "# symforce.set_log_level(\"warning\")\n",
    "symforce.set_log_level(\"ERROR\")\n",
    "print(f\"symforce uses {symforce.get_symbolic_api()} as backend\")\n",
    "\n",
    "from symforce.notebook_util import display\n",
    "import symforce.symbolic as sf\n",
    "from symforce.values import Values\n",
    "from symforce import ops\n",
    "from symforce.ops import StorageOps, GroupOps, LieGroupOps\n",
    "\n",
    "import symforce.opt.noise_models as nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6ec069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "  \n",
    "# ref: https://www.geeksforgeeks.org/timing-functions-with-decorators-python/\n",
    "disp_timecost = True \n",
    "def timer(func):\n",
    "    # This function shows the execution time of \n",
    "    # the function object passed\n",
    "    def wrap_func(*args, **kwargs):\n",
    "        t1 = time()\n",
    "        result = func(*args, **kwargs)\n",
    "        t2 = time()\n",
    "        \n",
    "        if disp_timecost:\n",
    "            print(f'Function {func.__name__} executed in {(t2-t1):.4f}s')\n",
    "\n",
    "        return result\n",
    "    return wrap_func\n",
    "\n",
    "def np2o3d(nx3mat):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(nx3mat)\n",
    "    return pcd\n",
    "\n",
    "def to_o3dlineset(points, corres_idxes):\n",
    "    if len(points) == 0:\n",
    "        return None\n",
    "    \n",
    "    return o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(np.array(points)),\n",
    "        lines=o3d.utility.Vector2iVector(np.array(corres_idxes)),\n",
    "    )\n",
    "\n",
    "def probabilistic_false_corres_idx(init_idx, num_max, outlier_ratio=0.5):\n",
    "    if np.random.rand(1) > outlier_ratio:\n",
    "        # return ture_correspondenceness, corres_idx\n",
    "        return init_idx, True\n",
    "    else:\n",
    "        return int(np.random.randint(num_max, size=(1)).squeeze()), False\n",
    "#         return 1, False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f528c55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_val type is <class 'symforce.geo.matrix.Matrix31'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model parameters (as symbolic)\n",
    "scale    = sf.V1.symbolic(\"s\")\n",
    "transvec = sf.V3.symbolic(\"t\")\n",
    "rotvec   = sf.V3.symbolic(\"Theta\") # i.e., angle-axis parametrization\n",
    "rotmat   = LieGroupOps.from_tangent(sf.Rot3, rotvec) # for debug, display(rotmat.to_rotation_matrix())\n",
    "\n",
    "# Redisual (loss function)\n",
    "#  note: the rotation 'matrix' is used to formulate the below constraint, \n",
    "#        but it was parametrized as a 3-dim vector 'rotvec'!\n",
    "p_src        = sf.V3.symbolic(\"p_src\")     # p means a single 3D point \n",
    "p_tgt        = sf.V3.symbolic(\"p_tgt\") \n",
    "p_tgt_est    = (rotmat * p_src)*scale + transvec # The constraint: (sR*p) + t == p'\n",
    "    # for the Sim(3) details, see Scale Drift-Aware Large Scale Monocular SLAM (RSS 2020)\n",
    "\n",
    "error_val = p_tgt - p_tgt_est\n",
    "print(f\"error_val type is {type(error_val)}\")\n",
    "\n",
    "def robust_loss(error_V3: sf.V3):\n",
    "    \"\"\"\n",
    "    see the class BarronNoiseModel(ScalarNoiseModel) definition in noise_models.py\n",
    "        alpha: Controls shape and convexity of the loss function. Notable values:\n",
    "            alpha = 2 -> L2 loss\n",
    "            alpha = 1 -> Pseudo-huber loss\n",
    "            alpha = 0 -> Cauchy loss\n",
    "            alpha = -2 -> Geman-McClure loss\n",
    "            alpha = -inf -> Welsch loss\n",
    "        delta: Determines the transition point from quadratic to robust. Similar to \"delta\" as used\n",
    "            by the pseudo-huber loss function.\n",
    "        scalar_information: Scalar representing the inverse of the variance of an element of the\n",
    "            unwhitened residual. Conceptually, we use \"scalar_information\" to whiten (in a\n",
    "            probabalistic sense) the unwhitened residual before passing it through the Barron loss.\n",
    "        x_epsilon: Small value used for handling the singularity at x == 0.\n",
    "        alpha_epsilon: Small value used for handling singularities around alpha.\n",
    "    \"\"\"\n",
    "\n",
    "    alpha = 0\n",
    "    delta = 0.1\n",
    "    scalar_information = 10\n",
    "    epsilon = 1.0e-6\n",
    "\n",
    "    noise_model = nm.BarronNoiseModel(\n",
    "        alpha=alpha, delta=delta, scalar_information=scalar_information, x_epsilon=epsilon\n",
    "    )\n",
    "\n",
    "    robustified_error = sf.V1(noise_model.error(error_V3)) # robust loss \n",
    "\n",
    "#     robustified_error = error_V3.compute_AtA() #non robust loss \n",
    "    \n",
    "    return robustified_error\n",
    "\n",
    "error_model = robust_loss(error_val) \n",
    "\n",
    "# residual jacobian\n",
    "#  this is the powerful moment of symforce. It automatically generate the Jacobian equations explicitly. \n",
    "Je_trans_model = error_model.jacobian(transvec)\n",
    "Je_rot_model = error_model.jacobian(rotvec)\n",
    "Je_scale_model = error_model.jacobian(scale)\n",
    "\n",
    "# residual debug \n",
    "is_vis_jacobians = False\n",
    "\n",
    "def disp_info(elm, name=''):\n",
    "    print(\"=========INFO==========\")\n",
    "    print(f\"The shape and equation of {name}:\")\n",
    "    display(elm.shape)\n",
    "    display(elm)\n",
    "    print(\"=======================\\n\")\n",
    "\n",
    "if is_vis_jacobians:\n",
    "    disp_info(error_model, 'error_model')\n",
    "    disp_info(Je_rot_model, 'Je_rot')\n",
    "    disp_info(Je_trans_model, 'Je_trans')\n",
    "    disp_info(Je_scale_model, 'scale')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad576453",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Sim(3) optimization state dimension \n",
    "ndim_state = 7\n",
    "ndim_loss = 1\n",
    "\n",
    "# The nonlinear icp alg. \n",
    "def evaluate_error_and_jacobian(src_pt: np.ndarray, tag_pt: np.ndarray, tf):\n",
    "    # note: transformation is 6dim vector on the tangent space (i.e., [rotvec, trans])  == lie algebra, aka se(3) (note that \"small\" se)\n",
    "    se3 = tf[:6] # [rotvec3dim, trans3dim]\n",
    "    s = tf[-1] # scale \n",
    "    \n",
    "    def inject_values(model):\n",
    "        model_evaluated = \\\n",
    "            model.subs({rotvec: sf.V3(se3[:3]), \\\n",
    "                        transvec: sf.V3(se3[3:]), \\\n",
    "                        scale: sf.V1(s), \\\n",
    "                        p_src: sf.V3(src_pt), \\\n",
    "                        p_tgt: sf.V3(tag_pt)})\n",
    "        return model_evaluated.to_numpy()\n",
    "        \n",
    "    error, Je_rot, Je_trans, Je_scale = \\\n",
    "        [inject_values(x) for x in [error_model, Je_rot_model, Je_trans_model, Je_scale_model]]\n",
    "\n",
    "    return error, Je_rot, Je_trans, Je_scale\n",
    "    \n",
    "@timer\n",
    "def icp_once(src, tgt, tf_init, skip=100, outlier_ratio=0.5, verbose=False):\n",
    "\n",
    "    num_iters = 30\n",
    "\n",
    "    for _iter in range(num_iters):\n",
    "        num_pts = src.shape[0]\n",
    "\n",
    "        correct_corres_points = []\n",
    "        correct_corres_indexes = []\n",
    "        false_corres_points = []\n",
    "        false_corres_indexes = []\n",
    "\n",
    "        H = np.zeros((ndim_state, ndim_state))\n",
    "        b = np.zeros((ndim_state, 1))\n",
    "\n",
    "        # 1. gathering measurements\n",
    "        #  these should be parallelized with only locking the H++ and b++ block. C++ would be a choice for this job.\n",
    "        for pt_idx in range(num_pts):\n",
    "\n",
    "            # if \"true\" correspondence is given (this is an tutorial for education purpose), \n",
    "            # using a few points okay ..\n",
    "            if pt_idx % (skip+_iter) != 0:\n",
    "                continue # to save time cost, ealry return\n",
    "\n",
    "            # Here, we directly use the true-known pair (because this is a tutorial for educational purpose :)\n",
    "            #  In practice, (src_pt, tgt_pt) should be a correspondence (e.g., found by FPFH local featuer, see https://pcl.readthedocs.io/projects/tutorials/en/latest/fpfh_estimation.html)\n",
    "            src_corres_idx = pt_idx \n",
    "            tgt_corres_idx, is_true_corres \\\n",
    "                = probabilistic_false_corres_idx(pt_idx, num_pts-1, outlier_ratio=outlier_ratio) # true \n",
    "\n",
    "            src_pt, tgt_pt = src[src_corres_idx, :], tgt[tgt_corres_idx, :]\n",
    "\n",
    "            e, Je_rot, Je_trans, Je_scale \\\n",
    "                = evaluate_error_and_jacobian(src_pt, tgt_pt, tf_init)\n",
    "                #   ps. To understand the details of this nonlinear iterative update steps, see http://www.diag.uniroma1.it//~labrococo/tutorial_icra_2016/icra16_slam_tutorial_grisetti.pdf \n",
    "                #       however, in the above slide's example, the jacobian was generated by hand as well as Euler angle space was used, not angle-axis.\n",
    "\n",
    "            J = np.hstack((Je_rot, Je_trans, Je_scale)) \n",
    "                # this is 1x7 \n",
    "                #   1 is observation error model's output dimension \n",
    "                #      (in this tutorial, the error model is a norm of 3-dim error-state vector)\n",
    "                #   7 is the state dimension\n",
    "\n",
    "            H = H + J.T @ J # H: 7x1 * 1x7 => thus H is 7x7\n",
    "            b = b + J.T @ e # b: 7x1 * 1x1 => thus b is 7x1\n",
    "\n",
    "            if verbose:\n",
    "                print(\"\\n=================\")\n",
    "                print(f\"{pt_idx} error is\\n{e.T}\")\n",
    "                print(f\"{pt_idx} Je_rot is\\n{Je_rot}\")\n",
    "                print(f\"{pt_idx} Je_trans is\\n{Je_trans}\")\n",
    "                print(f\"{pt_idx} J is\\n{J}\")\n",
    "                print(f\"{pt_idx} H is\\n{H}\")\n",
    "                print(f\"{pt_idx} b is\\n{b}\")\n",
    "\n",
    "            # debug \n",
    "            if is_true_corres:\n",
    "                correct_corres_points.append(src_pt)\n",
    "                correct_corres_points.append(tgt_pt)\n",
    "                correct_corres_indexes.append([len(correct_corres_indexes)*2, len(correct_corres_indexes)*2+1])\n",
    "            else:\n",
    "                false_corres_points.append(src_pt)\n",
    "                false_corres_points.append(tgt_pt)\n",
    "                false_corres_indexes.append([len(false_corres_indexes)*2, len(false_corres_indexes)*2+1])\n",
    "\n",
    "\n",
    "        # 2. update once \n",
    "        dtf = -np.linalg.solve(H, b).squeeze() # note the step direction is minus\n",
    "\n",
    "        # debug\n",
    "        correct_corres_line_set = to_o3dlineset(correct_corres_points, correct_corres_indexes)\n",
    "        false_corres_line_set = to_o3dlineset(false_corres_points, false_corres_indexes)\n",
    "        line_sets = {\"correct\": correct_corres_line_set, \n",
    "                     \"false\": false_corres_line_set}\n",
    "\n",
    "        # update \n",
    "        strange_update_alram_thres = 100.0\n",
    "        if np.linalg.norm(dtf) > strange_update_alram_thres:\n",
    "            # strange_update_alram_thres is just arbitrarily selected because this is a toy problem \n",
    "            # if a weired update is detected, do not apply it.  \n",
    "            print(f\"dtf norm: {np.linalg.norm(dtf):.3f} is weired. Thus reject to update.\")\n",
    "            break\n",
    "\n",
    "        tf_init = tf_init + dtf # updated within the tangent space\n",
    "        print(f\"the estimated relative tf for iter {_iter} is {tf_init}\")\n",
    "\n",
    "    tf = tf_init\n",
    "    return tf, line_sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07d5d96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 5205 points.\n",
      " The datset metric scale min [-1.0758  0.5284 -0.4984]\n",
      " The datset metric scale max [0.9524 1.9634 0.4083]\n",
      "\n",
      "true_rot_diff is\n",
      " [[-0.4226 -0.9063  0.    ]\n",
      " [ 0.9063 -0.4226  0.    ]\n",
      " [ 0.      0.      1.    ]]\n",
      "true_rot_diff_vec is\n",
      " [0.     0.     2.0071]\n",
      "true_trans_diff is\n",
      " [-0.1335  0.15    0.05  ]\n",
      "true_scale_diff is\n",
      " 5.0\n"
     ]
    }
   ],
   "source": [
    "# Data generatation  \n",
    "#  source \n",
    "dataset_name = \"dragon\"\n",
    "pcd0 = o3d.io.read_point_cloud(f'data/{dataset_name}.pcd')\n",
    "\n",
    "scale_up = 10\n",
    "pcd0_points_scaled_up = np.array(pcd0.points) * scale_up\n",
    "pcd0 = np2o3d(pcd0_points_scaled_up)\n",
    "print(pcd0)\n",
    "print(f\" The datset metric scale min {np.min(np.array(pcd0.points), 0)}\")\n",
    "print(f\" The datset metric scale max {np.max(np.array(pcd0.points), 0)}\")\n",
    "\n",
    "#  generate target \n",
    "def rpy2mat(rpy, deg=True):\n",
    "    return R.from_euler('xyz', rpy, degrees=deg).as_matrix()\n",
    "\n",
    "def rpy2vec(rpy, deg=True):\n",
    "    return R.from_euler('xyz', rpy, degrees=deg).as_rotvec()\n",
    "\n",
    "true_rot_diff_rpy = np.array([0, 0, 115]) # deg \n",
    "true_rot_diff = rpy2mat(true_rot_diff_rpy)\n",
    "true_rot_diff_vec = rpy2vec(true_rot_diff_rpy)\n",
    "true_trans_diff = np.array([-0.1335, 0.15, 0.05]) * (0.1*scale_up)\n",
    "true_scale_diff = 5.0\n",
    "\n",
    "print(f\"\\ntrue_rot_diff is\\n {true_rot_diff}\")\n",
    "print(f\"true_rot_diff_vec is\\n {true_rot_diff_vec}\")\n",
    "print(f\"true_trans_diff is\\n {true_trans_diff}\")\n",
    "print(f\"true_scale_diff is\\n {true_scale_diff}\")\n",
    "\n",
    "pcd1 = o3d.geometry.PointCloud()\n",
    "pcd1_Sim3_applied = true_scale_diff*(true_rot_diff @ np.array(pcd0.points).transpose()) + np.expand_dims(true_trans_diff, axis=-1)\n",
    "pcd1.points = o3d.utility.Vector3dVector(pcd1_Sim3_applied.transpose())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "496d33a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_guess is [0.0048 0.0236 2.0333 0.3317 0.6475 0.7038 3.5001]\n",
      "\n",
      "======================================\n",
      "  ==========   iter 0   ==========\n",
      "======================================\n",
      "the estimated relative tf for iter 0 is [-0.0696  0.1633  1.3009 -0.4944 -2.6389 -0.5627  4.1099]\n",
      "the estimated relative tf for iter 1 is [-0.0427 -0.1211  2.1058 -0.6627  0.5856  0.221   3.6314]\n",
      "the estimated relative tf for iter 2 is [ 0.0673  0.2448  2.1348 -0.728   0.7498 -0.2931  5.4387]\n",
      "the estimated relative tf for iter 3 is [ 0.0275 -0.0139  1.8686  0.4493 -0.5676 -0.3336  4.0735]\n",
      "the estimated relative tf for iter 4 is [-0.0127  0.0716  2.0854  0.125   0.3989  0.3285  5.4109]\n",
      "the estimated relative tf for iter 5 is [ 0.0577 -0.1367  1.917  -0.507  -0.2585 -0.0459  4.3936]\n",
      "the estimated relative tf for iter 6 is [-0.0451  0.0786  2.1446  0.0192  0.5348  0.2514  5.3781]\n",
      "the estimated relative tf for iter 7 is [ 0.0295 -0.1197  1.8778 -0.6727 -0.5461 -0.1267  4.1186]\n",
      "the estimated relative tf for iter 8 is [0.013  0.1831 2.0537 0.1787 0.4464 0.3521 4.9965]\n",
      "the estimated relative tf for iter 9 is [ 0.3345 -0.1709  1.9111 -0.6245 -0.5779 -0.0541  4.7859]\n",
      "the estimated relative tf for iter 10 is [-0.019   0.1377  2.0774  0.0359  0.3959 -0.1769  4.8602]\n",
      "the estimated relative tf for iter 11 is [ 0.0119 -0.0984  1.8845 -0.1562 -0.2705  0.2973  5.1115]\n",
      "the estimated relative tf for iter 12 is [-0.0472  0.0606  2.0075 -0.2804  0.054   0.091   4.8565]\n",
      "the estimated relative tf for iter 13 is [-0.042  -0.0056  1.9887 -0.0302  0.0865  0.1829  5.0408]\n",
      "the estimated relative tf for iter 14 is [-0.0757  0.0027  2.0256 -0.3518  0.3773  0.3742  4.8773]\n",
      "the estimated relative tf for iter 15 is [ 0.0502 -0.0458  1.9876 -0.0905 -0.0202 -0.0048  4.9553]\n",
      "the estimated relative tf for iter 16 is [-0.0258  0.0195  1.9967 -0.0587  0.1224  0.1769  5.0071]\n",
      "the estimated relative tf for iter 17 is [ 0.0557 -0.0158  2.0377 -0.3219  0.1998  0.1704  4.9748]\n",
      "the estimated relative tf for iter 18 is [-0.1428  0.0368  2.0327 -0.3051  0.2745 -0.0702  4.9995]\n",
      "the estimated relative tf for iter 19 is [ 0.0484  0.0109  1.9871 -0.0694 -0.0291 -0.0312  4.9094]\n",
      "the estimated relative tf for iter 20 is [-0.057  -0.0062  2.0069 -0.2195  0.0384  0.023   4.8689]\n",
      "the estimated relative tf for iter 21 is [-0.0068  0.0437  2.0123 -0.1887  0.2454 -0.1923  5.0031]\n",
      "the estimated relative tf for iter 22 is [-0.0199  0.0143  2.0006 -0.2777 -0.0329 -0.0095  4.9258]\n",
      "the estimated relative tf for iter 23 is [ 0.0098  0.0156  2.0447  0.2379 -0.1967 -0.0797  4.9827]\n",
      "the estimated relative tf for iter 24 is [-0.0454 -0.159   1.6986  0.6173 -1.4279  1.0229  4.8687]\n",
      "the estimated relative tf for iter 25 is [-0.0594  0.1605  2.0938 -0.3835  0.621  -0.6616  4.3926]\n",
      "the estimated relative tf for iter 26 is [-0.0042 -0.3261  2.0795 -1.0315  0.395   1.2379  4.5428]\n",
      "the estimated relative tf for iter 27 is [-0.0072  0.4842  1.9769  0.8023  0.2394 -1.3518  5.2859]\n",
      "the estimated relative tf for iter 28 is [ 0.1057 -0.507   2.0066 -1.3211 -0.2213  1.6063  3.8306]\n",
      "the estimated relative tf for iter 29 is [-0.1666  0.0002  1.8916  0.3445 -0.3001  0.8655  5.162 ]\n",
      "Function icp_once executed in 6.0993s\n",
      "\n",
      "==========estimation==========\n",
      "delta rotation:\n",
      "[[-0.3121 -0.943  -0.1155]\n",
      " [ 0.943  -0.3223  0.0832]\n",
      " [-0.1157 -0.0829  0.9898]]\n",
      "delta translation:\n",
      "[ 0.3445 -0.3001  0.8655]\n",
      "delta scale: 5.162\n",
      "\n",
      "======================================\n",
      "  ==========   iter 1   ==========\n",
      "======================================\n",
      "the estimated relative tf for iter 0 is [ 0.1188  0.141   0.2331 -1.2246  1.003  -0.8393  0.914 ]\n",
      "the estimated relative tf for iter 1 is [ 0.0206  0.0963 -0.0285 -0.0641 -0.1299 -0.8489  0.9861]\n",
      "the estimated relative tf for iter 2 is [ 0.1309  0.1167  0.1603 -0.7312  0.5926 -0.4961  0.9262]\n",
      "the estimated relative tf for iter 3 is [ 0.0337  0.1246  0.1114 -0.6272  0.4889 -0.7874  0.9715]\n",
      "the estimated relative tf for iter 4 is [ 0.0303  0.1445  0.1332 -0.6051  0.527  -0.8313  0.9634]\n",
      "the estimated relative tf for iter 5 is [ 0.0852  0.1022  0.1046 -0.605   0.4109 -0.6788  0.9559]\n",
      "the estimated relative tf for iter 6 is [ 0.1285  0.1707  0.0845 -0.4659  0.3144 -0.7134  0.9581]\n",
      "the estimated relative tf for iter 7 is [ 0.033   0.0988  0.114  -0.605   0.4167 -0.7897  0.9596]\n",
      "the estimated relative tf for iter 8 is [ 0.062   0.1288  0.1143 -0.6078  0.4869 -0.8465  0.971 ]\n",
      "the estimated relative tf for iter 9 is [ 0.0694  0.0928  0.1289 -1.1695  0.3598 -0.5505  0.8919]\n",
      "the estimated relative tf for iter 10 is [ 0.0779  0.1469  0.0992 -0.4187  0.4097 -0.8382  0.9872]\n",
      "the estimated relative tf for iter 11 is [ 0.0724  0.1242  0.0994 -0.6217  0.3475 -0.7347  0.9579]\n",
      "the estimated relative tf for iter 12 is [ 0.0437  0.1132  0.1665 -1.1362  0.5282 -0.7979  0.9121]\n",
      "the estimated relative tf for iter 13 is [ 0.1064  0.1252  0.0881 -0.4526  0.4256 -0.6441  0.9793]\n",
      "the estimated relative tf for iter 14 is [ 0.1175  0.1242  0.1295 -0.6898  0.3994 -0.7143  0.9327]\n",
      "the estimated relative tf for iter 15 is [ 0.0323  0.1426  0.0917 -0.5914  0.4001 -0.9058  0.9666]\n",
      "the estimated relative tf for iter 16 is [ 0.0672  0.1475  0.1118 -0.6443  0.3461 -0.7713  0.9372]\n",
      "the estimated relative tf for iter 17 is [ 0.0514  0.1514  0.098  -0.5225  0.4259 -0.8829  0.9842]\n",
      "the estimated relative tf for iter 18 is [ 0.067   0.1196  0.1093 -0.6069  0.3953 -0.7043  0.9572]\n",
      "the estimated relative tf for iter 19 is [ 0.0723  0.1249  0.1362 -0.8668  0.3981 -0.7366  0.9446]\n",
      "the estimated relative tf for iter 20 is [ 0.1014  0.1082  0.1021 -0.5978  0.2814 -0.5322  0.9452]\n",
      "the estimated relative tf for iter 21 is [ 0.0871  0.103   0.1253 -0.6309  0.5065 -0.61    0.9729]\n",
      "the estimated relative tf for iter 22 is [ 0.0962  0.0772  0.1036 -0.7912  0.0925 -0.5075  0.8905]\n",
      "the estimated relative tf for iter 23 is [ 0.0647  0.1873  0.1198 -0.6634  0.4888 -0.9565  0.9638]\n",
      "the estimated relative tf for iter 24 is [ 0.0964  0.0972  0.1125 -0.6655  0.4298 -0.5939  0.9495]\n",
      "the estimated relative tf for iter 25 is [ 0.0478  0.1291  0.1151 -0.6526  0.4502 -0.7929  0.9523]\n",
      "the estimated relative tf for iter 26 is [ 0.0845  0.1467  0.0822 -0.5418  0.3677 -0.7803  0.9608]\n",
      "the estimated relative tf for iter 27 is [ 0.0584  0.0943  0.0895 -0.5353  0.363  -0.7458  0.9519]\n",
      "the estimated relative tf for iter 28 is [ 0.0952  0.1772  0.0922 -0.6764  0.2772 -0.7973  0.9273]\n",
      "the estimated relative tf for iter 29 is [ 0.0798  0.0858  0.146  -0.7815  0.5119 -0.5579  0.9539]\n",
      "Function icp_once executed in 6.1381s\n",
      "\n",
      "==========estimation==========\n",
      "delta rotation:\n",
      "[[ 0.9857 -0.1417  0.0911]\n",
      " [ 0.1486  0.9862 -0.0731]\n",
      " [-0.0795  0.0856  0.9932]]\n",
      "delta translation:\n",
      "[-0.7815  0.5119 -0.5579]\n",
      "delta scale: 0.954\n",
      "\n",
      "======================================\n",
      "  ==========   iter 2   ==========\n",
      "======================================\n",
      "the estimated relative tf for iter 0 is [-0.0261  0.0525 -0.0269  0.1636 -0.1455 -0.2513  0.995 ]\n",
      "the estimated relative tf for iter 1 is [ 0.0089  0.0036 -0.0171  0.1092 -0.0547 -0.0472  0.9996]\n",
      "the estimated relative tf for iter 2 is [-0.0404  0.0752 -0.0335  0.1184 -0.1547 -0.3201  0.9814]\n",
      "the estimated relative tf for iter 3 is [ 0.0147  0.0043 -0.0328  0.1902 -0.0928 -0.065   1.0113]\n",
      "the estimated relative tf for iter 4 is [-0.0184  0.0319 -0.0329  0.0774  0.0245 -0.2795  1.0171]\n",
      "the estimated relative tf for iter 5 is [-0.1058  0.1077 -0.1389  0.1127 -0.7277 -0.7011  0.9815]\n",
      "the estimated relative tf for iter 6 is [ 0.0901 -0.0157  0.0473  0.1972  0.3387  0.2297  1.0103]\n",
      "the estimated relative tf for iter 7 is [-0.0769  0.0603 -0.0589  0.129  -0.2375 -0.4108  0.9913]\n",
      "the estimated relative tf for iter 8 is [-0.0482  0.0681  0.0081  0.0387  0.0827 -0.4331  0.9961]\n",
      "the estimated relative tf for iter 9 is [ 0.0403  0.0134 -0.0262  0.0629 -0.1061  0.0606  0.9918]\n",
      "the estimated relative tf for iter 10 is [-0.0186  0.0445 -0.0411  0.1633 -0.1453 -0.259   1.0045]\n",
      "the estimated relative tf for iter 11 is [-0.0079  0.0272 -0.0069 -0.0648 -0.1333 -0.0641  0.9772]\n",
      "the estimated relative tf for iter 12 is [-0.0148  0.0113 -0.0133 -0.0545 -0.1818 -0.2693  0.9713]\n",
      "the estimated relative tf for iter 13 is [ 0.0042  0.0458 -0.0529  0.2909 -0.1276 -0.1518  1.0245]\n",
      "the estimated relative tf for iter 14 is [ 0.0358  0.0489 -0.0232 -0.0031 -0.2099 -0.0138  0.9845]\n",
      "the estimated relative tf for iter 15 is [-0.0698 -0.0467 -0.047   0.117  -0.2383 -0.0891  0.9869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the estimated relative tf for iter 16 is [ 0.0449  0.0605 -0.0411  0.2268 -0.0976 -0.0769  1.0215]\n",
      "the estimated relative tf for iter 17 is [-0.0102  0.026  -0.0441  0.048  -0.2179 -0.0896  0.9862]\n",
      "the estimated relative tf for iter 18 is [ 0.0096  0.0682 -0.0103  0.1446  0.07   -0.2178  1.0204]\n",
      "the estimated relative tf for iter 19 is [-0.0284  0.0338 -0.0163  0.0289 -0.0501 -0.2446  0.9983]\n",
      "the estimated relative tf for iter 20 is [-0.0344  0.0296 -0.059   0.2496 -0.2578 -0.2017  1.007 ]\n",
      "the estimated relative tf for iter 21 is [ 0.0252  0.0378 -0.0472  0.0924 -0.2391 -0.1497  0.9915]\n",
      "the estimated relative tf for iter 22 is [0.0345 0.0236 0.0005 0.0642 0.0811 0.0081 1.0144]\n",
      "the estimated relative tf for iter 23 is [-0.0215  0.0473 -0.0276 -0.0303 -0.1501 -0.3389  0.9814]\n",
      "the estimated relative tf for iter 24 is [-0.0162  0.0329 -0.0343  0.222  -0.0759 -0.1956  1.013 ]\n",
      "the estimated relative tf for iter 25 is [-0.0115  0.013   0.0348 -0.2451  0.1277 -0.4207  0.9708]\n",
      "the estimated relative tf for iter 26 is [ 0.0421  0.1028 -0.1067  0.5935 -0.396  -0.3261  1.0356]\n",
      "the estimated relative tf for iter 27 is [-0.0614 -0.055  -0.0579  0.1708 -0.3125  0.0478  0.9779]\n",
      "the estimated relative tf for iter 28 is [ 0.0225  0.0721 -0.0445  0.276  -0.0903 -0.1887  1.0247]\n",
      "the estimated relative tf for iter 29 is [-0.0162  0.0458 -0.037   0.129  -0.1739 -0.2222  0.9912]\n",
      "Function icp_once executed in 6.2881s\n",
      "\n",
      "==========estimation==========\n",
      "delta rotation:\n",
      "[[ 0.9983  0.0366  0.046 ]\n",
      " [-0.0374  0.9992  0.0153]\n",
      " [-0.0454 -0.017   0.9988]]\n",
      "delta translation:\n",
      "[ 0.129  -0.1739 -0.2222]\n",
      "delta scale: 0.991\n",
      "\n",
      "======================================\n",
      "  ==========   iter 3   ==========\n",
      "======================================\n",
      "the estimated relative tf for iter 0 is [ 0.028  -0.0513  0.0164 -0.0084  0.1207  0.2304  1.0058]\n",
      "the estimated relative tf for iter 1 is [-0.0116  0.0029 -0.0069  0.0385  0.0458 -0.0235  1.0094]\n",
      "the estimated relative tf for iter 2 is [ 0.0146 -0.0014  0.002  -0.03   -0.0141  0.0269  1.0036]\n",
      "the estimated relative tf for iter 3 is [-0.0288 -0.0076  0.0071 -0.0523  0.0296 -0.1487  0.998 ]\n",
      "the estimated relative tf for iter 4 is [ 0.0355  0.0099 -0.0008  0.0367  0.0308  0.078   1.01  ]\n",
      "the estimated relative tf for iter 5 is [ 0.0277 -0.0097  0.0116  0.0656  0.1629  0.1322  1.0295]\n",
      "the estimated relative tf for iter 6 is [ 0.0265 -0.0132  0.001   0.0269  0.0303  0.1348  1.0138]\n",
      "the estimated relative tf for iter 7 is [-0.0184 -0.0068  0.0285 -0.1972  0.0484 -0.0857  0.9872]\n",
      "the estimated relative tf for iter 8 is [ 0.0252 -0.0006  0.0179  0.0087  0.1965  0.0804  1.0251]\n",
      "the estimated relative tf for iter 9 is [ 0.0167  0.0126  0.0251 -0.2409 -0.0062  0.0062  0.987 ]\n",
      "the estimated relative tf for iter 10 is [-0.0291 -0.0059  0.0058 -0.04    0.0264 -0.1323  1.0081]\n",
      "the estimated relative tf for iter 11 is [-0.0076 -0.0258  0.0037  0.06    0.1213  0.095   1.0312]\n",
      "the estimated relative tf for iter 12 is [ 0.0226 -0.0028  0.0062 -0.1443  0.0333  0.0189  1.0066]\n",
      "the estimated relative tf for iter 13 is [ 0.0196 -0.0126  0.0016  0.0699  0.0409  0.0947  1.0136]\n",
      "the estimated relative tf for iter 14 is [-0.0478 -0.0089  0.0087 -0.0688 -0.032  -0.1461  0.984 ]\n",
      "the estimated relative tf for iter 15 is [ 0.0263  0.0251  0.0194 -0.0723  0.0899 -0.0481  1.0158]\n",
      "the estimated relative tf for iter 16 is [-0.006  -0.0128  0.0126 -0.0132  0.0893 -0.0121  1.015 ]\n",
      "the estimated relative tf for iter 17 is [ 0.0024 -0.0158 -0.0379  0.1126 -0.2596 -0.0585  0.9749]\n",
      "the estimated relative tf for iter 18 is [ 0.028   0.0068 -0.0052  0.1448  0.0857  0.1054  1.0259]\n",
      "the estimated relative tf for iter 19 is [ 0.0038 -0.0014  0.0025  0.041   0.0131  0.1122  1.0208]\n",
      "the estimated relative tf for iter 20 is [ 0.0579  0.0898 -0.064   0.1846 -0.0881 -0.2408  1.0271]\n",
      "the estimated relative tf for iter 21 is [ 0.0246  0.0111  0.081  -0.1502  0.2032  0.1404  0.9723]\n",
      "the estimated relative tf for iter 22 is [ 0.0243 -0.0571 -0.0615  0.1299 -0.051   0.2629  1.0343]\n",
      "the estimated relative tf for iter 23 is [-0.0165  0.0058  0.027   0.0063  0.1914 -0.0406  1.0161]\n",
      "the estimated relative tf for iter 24 is [-0.0313  0.0082 -0.0213  0.0633 -0.0347 -0.1053  1.0128]\n",
      "the estimated relative tf for iter 25 is [ 0.0109 -0.0091  0.0183 -0.1031  0.123  -0.0221  0.9963]\n",
      "the estimated relative tf for iter 26 is [-0.0331  0.0248  0.0171 -0.0659  0.0922 -0.1185  0.9772]\n",
      "the estimated relative tf for iter 27 is [ 0.0381 -0.0296  0.0209 -0.103   0.1168  0.0791  1.0107]\n",
      "the estimated relative tf for iter 28 is [-0.0251 -0.0154 -0.0041 -0.0919  0.0488  0.1349  1.0033]\n",
      "the estimated relative tf for iter 29 is [ 0.0233 -0.0347 -0.0143  0.2017 -0.0696  0.3276  1.031 ]\n",
      "Function icp_once executed in 6.1610s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m     o3d\u001b[38;5;241m.\u001b[39mvisualization\u001b[38;5;241m.\u001b[39mdraw_geometries([pcd0_Sim3_before_update, pcd1, \\\n\u001b[1;32m     98\u001b[0m                                        line_sets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrect\u001b[39m\u001b[38;5;124m\"\u001b[39m], line_sets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m]], \\\n\u001b[1;32m     99\u001b[0m                                        window_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_iter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (gray: before update, blue: target)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# draw after \u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_geometries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpcd0_Sim3_after_update\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpcd1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mwindow_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miteration \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43m_iter\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m (sky: after updated, blue: target)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# 5. if tf_tangent is smaller than a threshold, stop \u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m==========estimation==========\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##########\n",
    "#  MAIN \n",
    "##########\n",
    "\n",
    "# At the very first status \n",
    "is_viz = 1\n",
    "if is_viz:\n",
    "    pcd0.paint_uniform_color([1, 0, 1])\n",
    "    pcd1.paint_uniform_color([0, 0, 1])\n",
    "    o3d.visualization.draw_geometries([pcd0, pcd1], window_name=\"initial status\")\n",
    "\n",
    "# Initial condition \n",
    "def gen_noisy_but_reliable_inital():\n",
    "    rot_init = R.from_euler('xyz', true_rot_diff_rpy, degrees=True).as_rotvec() + 0.05*np.random.rand(3)\n",
    "    trans_init = true_trans_diff + np.random.rand(3)*(0.1*scale_up)\n",
    "#     scale_init = np.random.rand(1) * true_scale_diff\n",
    "    scale_init = 0.7* true_scale_diff\n",
    "    \n",
    "    eps = 0.0001 # +eps means: because zero initial should be avoided (see the symbolic equation of Je_rot!)\n",
    "    initial_state_vector = np.hstack((rot_init, trans_init, scale_init)) + eps \n",
    "    return initial_state_vector\n",
    "\n",
    "def identity_inital():\n",
    "    eps = 0.0001\n",
    "    return np.array([eps, eps, eps, eps, eps, eps, 1.0])\n",
    "    # because after the update, the registered_src is expected to be equal to the target \n",
    "    # thus, the translation and rotataion would be zero and the relative scale must be 1.0\n",
    "\n",
    "init_guess = gen_noisy_but_reliable_inital() \n",
    "# init_guess = gen_noisy_but_reliable_inital() \n",
    "    # at the very first step, a moderate (i.e., not-identity) initial value is required \n",
    "    # because the cost function is highly nonlinear\n",
    "    # ps. try yourself using init_guess = identity_inital() rather than gen_noisy_but_reliable_inital()\n",
    "    #  the convergence speed would be deteriorated. (test yourself!)\n",
    "print(f\"init_guess is {init_guess}\")\n",
    "\n",
    "# NOTE\n",
    "# The number of correspondences and their spatial distirbution would affect the results\n",
    "# for example, \n",
    "# in the below example, \n",
    "# for the dragon dataset, it will converge (when we use the robust loss) even under 50% outliers while using skip=20\n",
    "# however, for the bunny dataset, which has the more smaller number of points, would not converge when we use skip=20 (skip=1 is then okay. try yourself!)\n",
    "    # ps. for the production level code, you also adaptively conclude when num_iters should be stopped in the icp_once (e.g., by tracking the df or residuals)\n",
    "        # by doing so, you need to prevent the solution from divergent.   \n",
    "# therefore, the what I want to say is for parameter tuning, we should well understand your dataset's characteristics (e.g., density, spatial distribution, etc.)\n",
    "\n",
    "# ICP starts  \n",
    "max_iter = 25\n",
    "src_pc, tgt_pc = [np.array(pc.points) for pc in [pcd0, pcd1]]\n",
    "for _iter in range(max_iter):\n",
    "    print(f\"\\n======================================\")\n",
    "    print(f\"  ==========   iter {_iter}   ==========\")\n",
    "    print(f\"======================================\")\n",
    "    # 1. optimize once \n",
    "    src_pc_before_updated = copy.deepcopy(src_pc)\n",
    "\n",
    "    outlier_ratio = 0.3 # test yourself up to 0.00 (no outlier) to 0.99\n",
    "    pts_skip = 20 # for bunny (num points are small), use skip = 1 and for the dragon, use skip=20 is okay\n",
    "    tf_tangent, line_sets = icp_once(src_pc, tgt_pc, init_guess, skip=pts_skip, \\\n",
    "                                     outlier_ratio=outlier_ratio,\n",
    "                                     verbose=False) # if \"true\" correspondence is given (this is an tutorial for education purpose), using a few iteration okay ..\n",
    "\n",
    "    # 2. move the src to target and \n",
    "    est_rot3, est_trans3, est_scale = tf_tangent[:3], tf_tangent[3:6], tf_tangent[-1]\n",
    "    est_rotmat3x3 = rotmat.subs({rotvec: sf.V3(est_rot3)}).to_rotation_matrix().to_numpy()\n",
    "    src_pc_updated = est_scale*(est_rotmat3x3 @ src_pc.transpose()) + np.array([est_trans3]).transpose()\n",
    "    src_pc = src_pc_updated.transpose()\n",
    "    \n",
    "    init_guess = identity_inital()\n",
    "    # note: we explicitly update the source point cloud (i.e., registered), \n",
    "        # thus from the next step, we will use init_guess always equal to identity (toy example assumption)\n",
    "        # because, as already mentioned, after the update, the registered_src is expected to be equal to the target \n",
    "        # thus, the translation and rotataion would be zero and the relative scale must be 1.0\n",
    "        # in real world example, we need to use a domain knowledge to update the better initial (e.g., constant motion model, the prior knowledge of the object's metric scale, etc.)\n",
    "\n",
    "    # 3. re-correspondence\n",
    "    #  here, we can use the known true-correspondence because this is just a tutorial and affine transformation does not change the true correspondences \n",
    "    #   but in real world applications, kd-tree-like nearest neighbor search to find a newaly updated correspondences is required. \n",
    "\n",
    "    # 4. debug: Verify the result visually \n",
    "    if is_viz:\n",
    "        pcd0_Sim3_before_update = np2o3d(src_pc_before_updated)\n",
    "        pcd0_Sim3_before_update.paint_uniform_color([0.5, 0.5, 0.5])\n",
    "        \n",
    "        pcd0_Sim3_after_update = np2o3d(src_pc)\n",
    "        pcd0_Sim3_after_update.paint_uniform_color([25./255, 158./255, 243./255])\n",
    "        \n",
    "        pcd1.paint_uniform_color([0, 0, 1])\n",
    "        \n",
    "        line_sets[\"correct\"].paint_uniform_color([0, 0.737, 0.354])\n",
    "        if line_sets[\"false\"] is None:\n",
    "            line_sets[\"false\"] = copy.deepcopy(line_sets[\"correct\"])\n",
    "        else:\n",
    "            line_sets[\"false\"].paint_uniform_color([1.0, 0.0, 0.0])\n",
    "        \n",
    "        # draw before \n",
    "        o3d.visualization.draw_geometries([pcd0_Sim3_before_update, pcd1, \\\n",
    "                                           line_sets[\"correct\"], line_sets[\"false\"]], \\\n",
    "                                           window_name=f\"iteration {_iter} (gray: before update, blue: target)\")\n",
    "        \n",
    "        # draw after \n",
    "        o3d.visualization.draw_geometries([pcd0_Sim3_after_update, pcd1], \\\n",
    "                                           window_name=f\"iteration {_iter} (sky: after updated, blue: target)\")\n",
    "\n",
    "    # 5. if tf_tangent is smaller than a threshold, stop \n",
    "    print(\"\\n==========estimation==========\")\n",
    "    print(f\"delta rotation:\\n{est_rotmat3x3}\")\n",
    "    print(f\"delta translation:\\n{est_trans3}\")\n",
    "    print(f\"delta scale: {est_scale:.3f}\")\n",
    "    # TBA, e.g., if delta_translation < 0.01, break;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1813e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Future work \n",
    "# Here, the false residual and its Hessian is directly incorporated within the normal equation \n",
    "# we can say this deweighting method implictily handles the outliers. \n",
    "# The next step you can do is to \"explictly remove\" the false correspondences from the pairs \n",
    "# e.g., using RANSAC "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
