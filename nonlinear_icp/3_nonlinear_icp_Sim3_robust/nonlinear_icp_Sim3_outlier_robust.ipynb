{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f90f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symforce uses symengine as backend\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import copy \n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "import open3d as o3d\n",
    "\n",
    "import symforce \n",
    "# symforce.set_log_level(\"warning\")\n",
    "symforce.set_log_level(\"ERROR\")\n",
    "print(f\"symforce uses {symforce.get_symbolic_api()} as backend\")\n",
    "\n",
    "from symforce.notebook_util import display\n",
    "import symforce.symbolic as sf\n",
    "from symforce.values import Values\n",
    "from symforce import ops\n",
    "from symforce.ops import StorageOps, GroupOps, LieGroupOps\n",
    "\n",
    "import symforce.opt.noise_models as nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a6ec069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "  \n",
    "# ref: https://www.geeksforgeeks.org/timing-functions-with-decorators-python/\n",
    "disp_timecost = True \n",
    "def timer(func):\n",
    "    # This function shows the execution time of \n",
    "    # the function object passed\n",
    "    def wrap_func(*args, **kwargs):\n",
    "        t1 = time()\n",
    "        result = func(*args, **kwargs)\n",
    "        t2 = time()\n",
    "        \n",
    "        if disp_timecost:\n",
    "            print(f'Function {func.__name__} executed in {(t2-t1):.4f}s')\n",
    "\n",
    "        return result\n",
    "    return wrap_func\n",
    "\n",
    "def np2o3d(nx3mat):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(nx3mat)\n",
    "    return pcd\n",
    "\n",
    "def to_o3dlineset(points, corres_idxes):\n",
    "    if len(points) == 0:\n",
    "        return None\n",
    "    \n",
    "    return o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(np.array(points)),\n",
    "        lines=o3d.utility.Vector2iVector(np.array(corres_idxes)),\n",
    "    )\n",
    "\n",
    "def probabilistic_false_corres_idx(init_idx, num_max, outlier_ratio=0.5):\n",
    "    if np.random.rand(1) > outlier_ratio:\n",
    "        # return ture_correspondenceness, corres_idx\n",
    "        return init_idx, True\n",
    "    else:\n",
    "        return int(np.random.randint(num_max, size=(1)).squeeze()), False # if want to use random false corres\n",
    "#         return 1, False # if want to use fixed false corres \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f528c55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_val type is <class 'symforce.geo.matrix.Matrix31'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model parameters (as symbolic)\n",
    "scale    = sf.V1.symbolic(\"s\")\n",
    "transvec = sf.V3.symbolic(\"t\")\n",
    "rotvec   = sf.V3.symbolic(\"Theta\") # i.e., angle-axis parametrization\n",
    "rotmat   = LieGroupOps.from_tangent(sf.Rot3, rotvec) # for debug, display(rotmat.to_rotation_matrix())\n",
    "\n",
    "# Redisual (loss function)\n",
    "#  note: the rotation 'matrix' is used to formulate the below constraint, \n",
    "#        but it was parametrized as a 3-dim vector 'rotvec'!\n",
    "p_src        = sf.V3.symbolic(\"p_src\")     # p means a single 3D point \n",
    "p_tgt        = sf.V3.symbolic(\"p_tgt\") \n",
    "\n",
    "# p_tgt_est    = (rotmat * p_src)*scale + transvec # bug. sometimes converges but sometimes weired behaviors \n",
    "p_tgt_est    = ((rotmat * p_src) + transvec)*scale # The constraint: see the eq149 of https://ethaneade.com/lie.pdf\n",
    "    # for the Sim(3) details, see\n",
    "        # Scale Drift-Aware Large Scale Monocular SLAM (RSS 2020)\n",
    "    # and see the eq149 of https://ethaneade.com/lie.pdf\n",
    "\n",
    "error_val = p_tgt - p_tgt_est\n",
    "print(f\"error_val type is {type(error_val)}\")\n",
    "\n",
    "def robust_loss(error_V3: sf.V3, robustness=True):\n",
    "    \"\"\"\n",
    "    see the class BarronNoiseModel(ScalarNoiseModel) definition in noise_models.py\n",
    "        alpha: Controls shape and convexity of the loss function. Notable values:\n",
    "            alpha = 2 -> L2 loss\n",
    "            alpha = 1 -> Pseudo-huber loss\n",
    "            alpha = 0 -> Cauchy loss\n",
    "            alpha = -2 -> Geman-McClure loss\n",
    "            alpha = -inf -> Welsch loss\n",
    "        delta: Determines the transition point from quadratic to robust. Similar to \"delta\" as used\n",
    "            by the pseudo-huber loss function.\n",
    "        scalar_information: Scalar representing the inverse of the variance of an element of the\n",
    "            unwhitened residual. Conceptually, we use \"scalar_information\" to whiten (in a\n",
    "            probabalistic sense) the unwhitened residual before passing it through the Barron loss.\n",
    "        x_epsilon: Small value used for handling the singularity at x == 0.\n",
    "        alpha_epsilon: Small value used for handling singularities around alpha.\n",
    "    \"\"\"\n",
    "\n",
    "    if robustness:\n",
    "        alpha = 0\n",
    "    else:\n",
    "        alpha = 2 \n",
    "        # then, this L2 loss would have equal effect of when we use the \n",
    "        # robustified_error = error_V3.compute_AtA() #non robust loss \n",
    "\n",
    "    delta = 0.2\n",
    "    scalar_information = 5.0\n",
    "    epsilon = 1.0e-6\n",
    "\n",
    "    noise_model = nm.BarronNoiseModel(\n",
    "        alpha=alpha, delta=delta, scalar_information=scalar_information, x_epsilon=epsilon\n",
    "    )\n",
    "\n",
    "    robustified_error = sf.V1(noise_model.error(error_V3))\n",
    "\n",
    "    return robustified_error\n",
    "\n",
    "\n",
    "# Core part of this tutorial \n",
    "robustness = True ### Try True and False yourself. \n",
    "error_model = robust_loss(error_val, robustness) \n",
    "\n",
    "# residual jacobian\n",
    "#  this is the powerful moment of symforce. It automatically generate the Jacobian equations explicitly. \n",
    "Je_trans_model = error_model.jacobian(transvec)\n",
    "Je_rot_model = error_model.jacobian(rotvec)\n",
    "Je_scale_model = error_model.jacobian(scale)\n",
    "\n",
    "# residual debug \n",
    "is_vis_jacobians = False \n",
    "\n",
    "def disp_info(elm, name=''):\n",
    "    print(\"=========INFO==========\")\n",
    "    print(f\"The shape and equation of {name}:\")\n",
    "    display(elm.shape)\n",
    "    display(elm)\n",
    "    print(\"=======================\\n\")\n",
    "\n",
    "if is_vis_jacobians:\n",
    "    disp_info(error_model, 'error_model')\n",
    "    disp_info(Je_rot_model, 'Je_rot')\n",
    "    disp_info(Je_trans_model, 'Je_trans')\n",
    "    disp_info(Je_scale_model, 'scale')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad576453",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Sim(3) optimization state dimension \n",
    "ndim_state = 7\n",
    "ndim_loss = 1\n",
    "\n",
    "# The nonlinear icp alg. \n",
    "def evaluate_error_and_jacobian(src_pt: np.ndarray, tag_pt: np.ndarray, tf):\n",
    "    # note: transformation is 6dim vector on the tangent space (i.e., [rotvec, trans])  == lie algebra, aka se(3) (note that \"small\" se)\n",
    "    se3 = tf[:6] # [rotvec3dim, trans3dim]\n",
    "    s = tf[-1] # scale \n",
    "    \n",
    "    def inject_values(model):\n",
    "        model_evaluated = \\\n",
    "            model.subs({rotvec: sf.V3(se3[:3]), \\\n",
    "                        transvec: sf.V3(se3[3:]), \\\n",
    "                        scale: sf.V1(s), \\\n",
    "                        p_src: sf.V3(src_pt), \\\n",
    "                        p_tgt: sf.V3(tag_pt)})\n",
    "        return model_evaluated.to_numpy()\n",
    "        \n",
    "    error, Je_rot, Je_trans, Je_scale = \\\n",
    "        [inject_values(x) for x in [error_model, Je_rot_model, Je_trans_model, Je_scale_model]]\n",
    "\n",
    "    return error, Je_rot, Je_trans, Je_scale\n",
    "    \n",
    "@timer\n",
    "def icp_once(src, tgt, tf_init, skip=100, outlier_ratio=0.5, num_iters=30, fix_scale=False, verbose=False):\n",
    "\n",
    "    for _iter in range(num_iters):\n",
    "        num_pts = src.shape[0]\n",
    "\n",
    "        correct_corres_points = []\n",
    "        correct_corres_indexes = []\n",
    "        false_corres_points = []\n",
    "        false_corres_indexes = []\n",
    "\n",
    "        H = np.zeros((ndim_state, ndim_state))\n",
    "        b = np.zeros((ndim_state, 1))\n",
    "\n",
    "        # 1. gathering measurements\n",
    "        #  these should be parallelized with only locking the H++ and b++ block. C++ would be a choice for this job.\n",
    "        for pt_idx in range(num_pts):\n",
    "\n",
    "            # if \"true\" correspondence is given (this is an tutorial for education purpose), \n",
    "            # using a few points okay ..\n",
    "            if pt_idx % (skip+_iter) != 0:\n",
    "                continue # to save time cost, ealry return\n",
    "\n",
    "            # Here, we directly use the true-known pair (because this is a tutorial for educational purpose :)\n",
    "            #  In practice, (src_pt, tgt_pt) should be a correspondence (e.g., found by FPFH local featuer, see https://pcl.readthedocs.io/projects/tutorials/en/latest/fpfh_estimation.html)\n",
    "            src_corres_idx = pt_idx \n",
    "            tgt_corres_idx, is_true_corres \\\n",
    "                = probabilistic_false_corres_idx(pt_idx, num_pts-1, outlier_ratio=outlier_ratio) # true \n",
    "\n",
    "            src_pt, tgt_pt = src[src_corres_idx, :], tgt[tgt_corres_idx, :]\n",
    "            \n",
    "            e, Je_rot, Je_trans, Je_scale \\\n",
    "                = evaluate_error_and_jacobian(src_pt, tgt_pt, tf_init)\n",
    "                #   ps. To understand the details of this nonlinear iterative update steps, see http://www.diag.uniroma1.it//~labrococo/tutorial_icra_2016/icra16_slam_tutorial_grisetti.pdf \n",
    "                #       however, in the above slide's example, the jacobian was generated by hand as well as Euler angle space was used, not angle-axis.\n",
    "\n",
    "            if fix_scale:\n",
    "                e[-1] = 0.000001\n",
    "                Je_scale = np.array([[1]])\n",
    "\n",
    "            J = np.hstack((Je_rot, Je_trans, Je_scale)) \n",
    "                # this is 1x7 \n",
    "                #   1 is observation error model's output dimension \n",
    "                #      (in this tutorial, the error model is a norm of 3-dim error-state vector)\n",
    "                #   7 is the state dimension\n",
    "\n",
    "            sqrtW = np.array([[1., 1., 1., 1., 1., 1., 1.]]) # trying change yourself :) \n",
    "            J = sqrtW * J # whitened J. (element-wise multiplication)\n",
    "                            # i.e., J.t@W@J == (sqrtW@J).t @ (sqrtW@J) == ||sqrtW@J||2\n",
    "                          # In this case, make lower the sensitivity of the scale term will be benefit for the convergnece. \n",
    "                          #  This is an engineering. you should apply your physical prior or domain knowledge, or even empirically find it.\n",
    "            e[:3] *= 1.0 # this is also empirically important. \n",
    "            e[-1] *= 0.3 # this is also empirically important. \n",
    "                          # because translation changes along a few meters, but rotation and scales are lives in [0, 1]\n",
    "            \n",
    "            H = H + (J.T @ J) # H: 7x1 * 1x7 => thus H is 7x7\n",
    "            b = b + (J.T @ e) # b: 7x1 * 1x1 => thus b is 7x1\n",
    "                # to understatand the update eq, see https://darkpgmr.tistory.com/142\n",
    "\n",
    "            if verbose:\n",
    "                print(\"\\n=================\")\n",
    "                print(f\"{pt_idx} error is\\n{e.T}\")\n",
    "                print(f\"{pt_idx} Je_rot is\\n{Je_rot}\")\n",
    "                print(f\"{pt_idx} Je_trans is\\n{Je_trans}\")\n",
    "                print(f\"{pt_idx} J is\\n{J}\")\n",
    "                print(f\"{pt_idx} H is\\n{H}\")\n",
    "                print(f\"{pt_idx} b is\\n{b}\")\n",
    "\n",
    "            # debug \n",
    "            if is_true_corres:\n",
    "                correct_corres_points.append(src_pt)\n",
    "                correct_corres_points.append(tgt_pt)\n",
    "                correct_corres_indexes.append([len(correct_corres_indexes)*2, len(correct_corres_indexes)*2+1])\n",
    "            else:\n",
    "                false_corres_points.append(src_pt)\n",
    "                false_corres_points.append(tgt_pt)\n",
    "                false_corres_indexes.append([len(false_corres_indexes)*2, len(false_corres_indexes)*2+1])\n",
    "\n",
    "\n",
    "        # 2. update once \n",
    "        dtf = -np.linalg.solve(H, b).squeeze() # note the step direction is minus\n",
    "\n",
    "        \n",
    "        # debug\n",
    "        correct_corres_line_set = to_o3dlineset(correct_corres_points, correct_corres_indexes)\n",
    "        false_corres_line_set = to_o3dlineset(false_corres_points, false_corres_indexes)\n",
    "        line_sets = {\"correct\": correct_corres_line_set, \n",
    "                     \"false\": false_corres_line_set}\n",
    "\n",
    "        # update \n",
    "        strange_update_alram_thres = 100.0\n",
    "        if np.linalg.norm(dtf) > strange_update_alram_thres:\n",
    "            # strange_update_alram_thres is just arbitrarily selected because this is a toy problem \n",
    "            # if a weired update is detected, do not apply it.  \n",
    "            print(f\"dtf norm: {np.linalg.norm(dtf):.3f} is weired. Thus reject to update.\")\n",
    "            break\n",
    "\n",
    "        tf_init = tf_init + dtf # updated within the tangent space\n",
    "        print(f\"the estimated relative tf for iter {_iter} is {tf_init}\")\n",
    "\n",
    "    # final result \n",
    "    tf = tf_init\n",
    "\n",
    "    return tf, line_sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07d5d96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 5205 points.\n",
      " The datset metric scale min [-1.0758  0.5284 -0.4984]\n",
      " The datset metric scale max [0.9524 1.9634 0.4083]\n",
      "\n",
      "true_rot_diff is\n",
      " [[-0.4226 -0.9063  0.    ]\n",
      " [ 0.9063 -0.4226  0.    ]\n",
      " [ 0.      0.      1.    ]]\n",
      "true_rot_diff_vec is\n",
      " [0.     0.     2.0071]\n",
      "true_trans_diff is\n",
      " [-0.1335  0.15    0.05  ]\n",
      "true_scale_diff is\n",
      " 5.0\n"
     ]
    }
   ],
   "source": [
    "# Data generatation  \n",
    "#  source \n",
    "dataset_name = \"dragon\"\n",
    "pcd0 = o3d.io.read_point_cloud(f'data/{dataset_name}.pcd')\n",
    "\n",
    "scale_up = 10\n",
    "pcd0_points_scaled_up = np.array(pcd0.points) * scale_up\n",
    "pcd0 = np2o3d(pcd0_points_scaled_up)\n",
    "print(pcd0)\n",
    "print(f\" The datset metric scale min {np.min(np.array(pcd0.points), 0)}\")\n",
    "print(f\" The datset metric scale max {np.max(np.array(pcd0.points), 0)}\")\n",
    "\n",
    "#  generate target \n",
    "def rpy2mat(rpy, deg=True):\n",
    "    return R.from_euler('xyz', rpy, degrees=deg).as_matrix()\n",
    "\n",
    "def rpy2vec(rpy, deg=True):\n",
    "    return R.from_euler('xyz', rpy, degrees=deg).as_rotvec()\n",
    "\n",
    "true_rot_diff_rpy = np.array([0, 0, 115]) # deg \n",
    "true_rot_diff = rpy2mat(true_rot_diff_rpy)\n",
    "true_rot_diff_vec = rpy2vec(true_rot_diff_rpy)\n",
    "true_trans_diff = np.array([-0.1335, 0.15, 0.05]) * (0.1*scale_up)\n",
    "true_scale_diff = 5.0\n",
    "\n",
    "print(f\"\\ntrue_rot_diff is\\n {true_rot_diff}\")\n",
    "print(f\"true_rot_diff_vec is\\n {true_rot_diff_vec}\")\n",
    "print(f\"true_trans_diff is\\n {true_trans_diff}\")\n",
    "print(f\"true_scale_diff is\\n {true_scale_diff}\")\n",
    "\n",
    "pcd1 = o3d.geometry.PointCloud()\n",
    "pcd1_Sim3_applied = true_scale_diff*(true_rot_diff @ np.array(pcd0.points).transpose()) + np.expand_dims(true_trans_diff, axis=-1)\n",
    "pcd1.points = o3d.utility.Vector3dVector(pcd1_Sim3_applied.transpose())\n",
    "    \n",
    "# At the very first status \n",
    "is_viz = 1\n",
    "if is_viz:\n",
    "    pcd0.paint_uniform_color([1, 0, 1])\n",
    "    pcd1.paint_uniform_color([0, 0, 1])\n",
    "    o3d.visualization.draw_geometries([pcd0, pcd1], window_name=\"initial status\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "496d33a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_guess is [0.0196 0.0451 2.0547 0.2301 1.106  0.296  3.5001]\n",
      "\n",
      "======================================\n",
      "  =========   refine 0   ==========\n",
      "======================================\n",
      "the estimated relative tf for iter 0 is [0.0101 0.0342 2.0629 0.1255 1.0749 0.2846 3.2138]\n",
      "the estimated relative tf for iter 1 is [0.0032 0.0095 2.0576 0.0322 1.0187 0.2883 2.9983]\n",
      "the estimated relative tf for iter 2 is [-0.0236 -0.0151  2.0722 -0.0748  1.0073  0.297   2.8517]\n",
      "the estimated relative tf for iter 3 is [-0.0185 -0.0356  2.1111 -0.1711  1.0005  0.29    2.7422]\n",
      "the estimated relative tf for iter 4 is [-0.0168 -0.0592  2.1052 -0.2412  0.9633  0.2847  2.6451]\n",
      "the estimated relative tf for iter 5 is [-0.0367 -0.0788  2.1037 -0.2919  0.8899  0.2823  2.6088]\n",
      "the estimated relative tf for iter 6 is [-0.0415 -0.0932  2.1117 -0.3441  0.8583  0.2738  2.5769]\n",
      "the estimated relative tf for iter 7 is [-0.0565 -0.1082  2.1196 -0.3997  0.8274  0.2679  2.5491]\n",
      "the estimated relative tf for iter 8 is [-0.0796 -0.1221  2.1198 -0.445   0.8059  0.2672  2.5269]\n",
      "the estimated relative tf for iter 9 is [-0.0966 -0.1489  2.1423 -0.4708  0.7677  0.2761  2.5778]\n",
      "the estimated relative tf for iter 10 is [-0.0887 -0.1566  2.1487 -0.4899  0.739   0.2553  2.5948]\n",
      "the estimated relative tf for iter 11 is [-0.0789 -0.1479  2.1598 -0.4934  0.6897  0.2334  2.6638]\n",
      "the estimated relative tf for iter 12 is [-0.0887 -0.1468  2.1439 -0.4862  0.6289  0.226   2.7077]\n",
      "the estimated relative tf for iter 13 is [-0.0836 -0.1378  2.1305 -0.4677  0.5867  0.2007  2.7704]\n",
      "the estimated relative tf for iter 14 is [-0.0783 -0.1334  2.1298 -0.4744  0.5598  0.1841  2.7968]\n",
      "the estimated relative tf for iter 15 is [-0.085  -0.1275  2.1378 -0.4637  0.5358  0.172   2.8947]\n",
      "the estimated relative tf for iter 16 is [-0.0732 -0.1144  2.1397 -0.4497  0.5083  0.152   2.9676]\n",
      "the estimated relative tf for iter 17 is [-0.0671 -0.1143  2.1488 -0.4278  0.4761  0.1459  3.0753]\n",
      "the estimated relative tf for iter 18 is [-0.0606 -0.101   2.1292 -0.3915  0.4278  0.1301  3.1758]\n",
      "the estimated relative tf for iter 19 is [-0.0534 -0.0931  2.1224 -0.378   0.3997  0.1169  3.2039]\n",
      "Function icp_once executed in 7.2368s\n",
      "\n",
      "==========estimation==========\n",
      "delta rotation:\n",
      "[[-0.5254 -0.8475 -0.0756]\n",
      " [ 0.8508 -0.5234 -0.0454]\n",
      " [-0.001  -0.0882  0.9961]]\n",
      "delta translation:\n",
      "[-0.378   0.3997  0.1169]\n",
      "delta scale: 3.204\n",
      "\n",
      "======================================\n",
      "  =========   refine 1   ==========\n",
      "======================================\n",
      "the estimated relative tf for iter 0 is [ 0.0023  0.0209 -0.0069 -0.0162 -0.0494 -0.0246  1.0125]\n",
      "the estimated relative tf for iter 1 is [-0.005   0.0258 -0.0114 -0.0722 -0.0699 -0.0479  1.0248]\n",
      "the estimated relative tf for iter 2 is [-0.0131  0.0321 -0.0186 -0.0878 -0.1021 -0.0695  1.0393]\n",
      "the estimated relative tf for iter 3 is [-0.0213  0.0373 -0.03   -0.1119 -0.1391 -0.0845  1.0539]\n",
      "the estimated relative tf for iter 4 is [-0.0285  0.0385 -0.0365 -0.1567 -0.1627 -0.0964  1.0607]\n",
      "the estimated relative tf for iter 5 is [-0.0359  0.0415 -0.0452 -0.1508 -0.195  -0.0979  1.0782]\n",
      "the estimated relative tf for iter 6 is [-0.0356  0.0471 -0.0541 -0.1603 -0.2201 -0.1098  1.0921]\n",
      "the estimated relative tf for iter 7 is [-0.0399  0.0516 -0.0475 -0.2337 -0.2004 -0.1288  1.1028]\n",
      "the estimated relative tf for iter 8 is [-0.0442  0.0526 -0.046  -0.254  -0.1931 -0.1353  1.1142]\n",
      "the estimated relative tf for iter 9 is [-0.0422  0.0549 -0.0515 -0.266  -0.22   -0.1384  1.1247]\n",
      "the estimated relative tf for iter 10 is [-0.0456  0.0575 -0.0577 -0.279  -0.2377 -0.1481  1.1327]\n",
      "the estimated relative tf for iter 11 is [-0.0451  0.0567 -0.0589 -0.2791 -0.242  -0.135   1.1456]\n",
      "the estimated relative tf for iter 12 is [-0.0441  0.055  -0.0601 -0.2617 -0.2483 -0.1124  1.1637]\n",
      "the estimated relative tf for iter 13 is [-0.044   0.0567 -0.066  -0.2595 -0.2647 -0.1135  1.1764]\n",
      "the estimated relative tf for iter 14 is [-0.0452  0.0552 -0.0648 -0.2616 -0.2729 -0.1086  1.188 ]\n",
      "the estimated relative tf for iter 15 is [-0.0476  0.0615 -0.0668 -0.2487 -0.2797 -0.1258  1.2032]\n",
      "the estimated relative tf for iter 16 is [-0.0448  0.0633 -0.0695 -0.2394 -0.2988 -0.1292  1.2172]\n",
      "the estimated relative tf for iter 17 is [-0.0479  0.0614 -0.0701 -0.22   -0.3137 -0.1245  1.2335]\n",
      "the estimated relative tf for iter 18 is [-0.048   0.064  -0.0736 -0.2043 -0.3267 -0.124   1.2463]\n",
      "the estimated relative tf for iter 19 is [-0.0469  0.07   -0.0828 -0.1773 -0.3492 -0.1309  1.2612]\n",
      "Function icp_once executed in 7.0600s\n",
      "\n",
      "==========estimation==========\n",
      "delta rotation:\n",
      "[[ 0.9941  0.0809  0.0718]\n",
      " [-0.0842  0.9955  0.0439]\n",
      " [-0.0679 -0.0497  0.9965]]\n",
      "delta translation:\n",
      "[-0.1773 -0.3492 -0.1309]\n",
      "delta scale: 1.261\n",
      "\n",
      "======================================\n",
      "  =========   refine 2   ==========\n",
      "======================================\n",
      "the estimated relative tf for iter 0 is [ 0.0076  0.0073  0.0063 -0.0046 -0.017   0.0077  1.0015]\n",
      "the estimated relative tf for iter 1 is [ 0.0074  0.0047  0.0032  0.0025 -0.0349  0.0117  1.0084]\n",
      "the estimated relative tf for iter 2 is [ 0.0065  0.0022  0.0008  0.0082 -0.0492  0.0143  1.0166]\n",
      "the estimated relative tf for iter 3 is [ 0.0067 -0.0001 -0.0019  0.0225 -0.0559  0.0196  1.0245]\n",
      "the estimated relative tf for iter 4 is [ 0.0035 -0.0013 -0.0054  0.0247 -0.0754  0.0168  1.0301]\n",
      "the estimated relative tf for iter 5 is [ 0.0036 -0.0012 -0.0095  0.0243 -0.091   0.0096  1.0346]\n",
      "the estimated relative tf for iter 6 is [ 0.002  -0.0021 -0.0104  0.0251 -0.1063  0.0076  1.0399]\n",
      "the estimated relative tf for iter 7 is [ 0.0031  0.003  -0.0155  0.0557 -0.1249 -0.0052  1.048 ]\n",
      "the estimated relative tf for iter 8 is [ 0.0006  0.0011 -0.0152  0.0675 -0.125  -0.0058  1.0545]\n",
      "the estimated relative tf for iter 9 is [ 0.0026 -0.0078 -0.0191  0.0731 -0.1373  0.0294  1.0589]\n",
      "the estimated relative tf for iter 10 is [-0.0012 -0.0061 -0.0216  0.0799 -0.1464  0.0122  1.0636]\n",
      "the estimated relative tf for iter 11 is [ 0.0001 -0.0047 -0.0249  0.0896 -0.1603  0.0131  1.0693]\n",
      "the estimated relative tf for iter 12 is [ 0.0053 -0.0059 -0.0226  0.081  -0.1605  0.0242  1.0727]\n",
      "the estimated relative tf for iter 13 is [ 0.002  -0.0037 -0.0214  0.0868 -0.1553  0.0134  1.0789]\n",
      "the estimated relative tf for iter 14 is [-0.0003 -0.003  -0.0252  0.0945 -0.1673  0.0102  1.083 ]\n",
      "the estimated relative tf for iter 15 is [ 0.0054  0.0035 -0.0271  0.0968 -0.1876 -0.0039  1.0871]\n",
      "the estimated relative tf for iter 16 is [ 0.0038  0.0115 -0.0248  0.101  -0.1741 -0.0395  1.0908]\n",
      "the estimated relative tf for iter 17 is [ 0.0022  0.0132 -0.0313  0.1229 -0.1952 -0.0627  1.095 ]\n",
      "the estimated relative tf for iter 18 is [ 0.0006  0.0178 -0.0296  0.1364 -0.1851 -0.0779  1.0994]\n",
      "the estimated relative tf for iter 19 is [ 0.0032  0.0204 -0.0311  0.1476 -0.189  -0.0848  1.104 ]\n",
      "Function icp_once executed in 6.5598s\n",
      "\n",
      "==========estimation==========\n",
      "delta rotation:\n",
      "[[ 0.9993  0.0312  0.0204]\n",
      " [-0.0311  0.9995 -0.0035]\n",
      " [-0.0205  0.0029  0.9998]]\n",
      "delta translation:\n",
      "[ 0.1476 -0.189  -0.0848]\n",
      "delta scale: 1.104\n",
      "\n",
      "======================================\n",
      "  =========   refine 3   ==========\n",
      "======================================\n",
      "the estimated relative tf for iter 0 is [0.0099 0.0098 0.0089 0.0116 0.0031 0.008  1.0023]\n",
      "the estimated relative tf for iter 1 is [ 0.0097  0.0055  0.0063  0.0124 -0.0126  0.0245  1.0036]\n",
      "the estimated relative tf for iter 2 is [ 0.0091 -0.0017  0.0069  0.0107 -0.0153  0.0531  1.0051]\n",
      "the estimated relative tf for iter 3 is [ 0.0099 -0.0062  0.004   0.0159 -0.0332  0.0682  1.0061]\n",
      "the estimated relative tf for iter 4 is [ 0.0064 -0.0157  0.0049  0.0147 -0.0352  0.0945  1.0068]\n",
      "the estimated relative tf for iter 5 is [ 0.0048 -0.0058  0.0042  0.0262 -0.0362  0.0488  1.0104]\n",
      "the estimated relative tf for iter 6 is [ 0.0089 -0.0046  0.0036  0.0231 -0.0447  0.0528  1.0118]\n",
      "the estimated relative tf for iter 7 is [ 0.0097 -0.0087  0.0046  0.0165 -0.0443  0.0762  1.0135]\n",
      "the estimated relative tf for iter 8 is [ 0.006  -0.0187  0.0025  0.0143 -0.0622  0.1072  1.014 ]\n",
      "the estimated relative tf for iter 9 is [ 0.0054 -0.0125 -0.      0.0354 -0.0646  0.0728  1.018 ]\n",
      "the estimated relative tf for iter 10 is [ 0.0051 -0.0072 -0.0019  0.0495 -0.0687  0.0517  1.0212]\n",
      "the estimated relative tf for iter 11 is [-0.0018 -0.0075 -0.0027  0.0486 -0.075   0.0348  1.0221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the estimated relative tf for iter 12 is [-0.0017 -0.0197 -0.0062  0.0388 -0.0932  0.0907  1.0214]\n",
      "the estimated relative tf for iter 13 is [-0.0037 -0.0313 -0.0074  0.0357 -0.0996  0.1414  1.0229]\n",
      "the estimated relative tf for iter 14 is [-0.     -0.0302 -0.0113  0.0405 -0.1194  0.1446  1.0242]\n",
      "the estimated relative tf for iter 15 is [ 0.0024 -0.0178 -0.0113  0.049  -0.1242  0.097   1.0257]\n",
      "the estimated relative tf for iter 16 is [-0.0037 -0.0083 -0.0056  0.0379 -0.1012  0.0326  1.0263]\n",
      "the estimated relative tf for iter 17 is [-0.0002 -0.0156 -0.0039  0.0379 -0.098   0.0685  1.0273]\n",
      "the estimated relative tf for iter 18 is [ 0.0007 -0.0134 -0.0038  0.0446 -0.0973  0.0621  1.0291]\n",
      "the estimated relative tf for iter 19 is [-0.0035 -0.0169  0.0029  0.0335 -0.0694  0.0754  1.0306]\n",
      "Function icp_once executed in 6.2426s\n",
      "\n",
      "==========estimation==========\n",
      "delta rotation:\n",
      "[[ 0.9999 -0.0029 -0.0169]\n",
      " [ 0.0029  1.      0.0035]\n",
      " [ 0.0169 -0.0036  0.9999]]\n",
      "delta translation:\n",
      "[ 0.0335 -0.0694  0.0754]\n",
      "delta scale: 1.031\n",
      "\n",
      "======================================\n",
      "  =========   refine 4   ==========\n",
      "======================================\n",
      "the estimated relative tf for iter 0 is [ 0.008   0.0025  0.0076  0.0076 -0.0106  0.0314  0.9995]\n",
      "the estimated relative tf for iter 1 is [ 0.0073  0.0047  0.0055  0.0069 -0.0149  0.0107  0.9995]\n",
      "the estimated relative tf for iter 2 is [ 0.0101 -0.0038  0.0028  0.0078 -0.0234  0.0561  0.9997]\n",
      "the estimated relative tf for iter 3 is [ 0.0123  0.0089 -0.0012  0.0175 -0.0402 -0.0023  0.9996]\n",
      "the estimated relative tf for iter 4 is [ 0.0075  0.0127 -0.0019  0.0266 -0.0369 -0.0306  1.0015]\n",
      "the estimated relative tf for iter 5 is [ 0.008   0.0104 -0.0031  0.0329 -0.0442 -0.024   1.0028]\n",
      "the estimated relative tf for iter 6 is [ 0.0067  0.0109 -0.0007  0.0334 -0.028  -0.0222  1.0051]\n",
      "the estimated relative tf for iter 7 is [ 0.0063  0.0066 -0.0008  0.0311 -0.0268  0.0011  1.0062]\n",
      "the estimated relative tf for iter 8 is [ 0.0073  0.0035 -0.0045  0.0404 -0.0415  0.0153  1.0067]\n",
      "the estimated relative tf for iter 9 is [ 0.0075  0.0026 -0.0054  0.0422 -0.0442  0.0208  1.0076]\n",
      "the estimated relative tf for iter 10 is [ 0.0012  0.0168  0.0006  0.0438 -0.0072 -0.0583  1.0106]\n",
      "the estimated relative tf for iter 11 is [ 0.0003  0.0168 -0.0027  0.0512 -0.0198 -0.0627  1.0112]\n",
      "the estimated relative tf for iter 12 is [-0.0032  0.0093 -0.0039  0.0485 -0.0221 -0.0392  1.0113]\n",
      "the estimated relative tf for iter 13 is [-0.0048  0.0196 -0.0096  0.0663 -0.0445 -0.0835  1.0126]\n",
      "the estimated relative tf for iter 14 is [-0.0028  0.017  -0.0065  0.0559 -0.0248 -0.0778  1.0127]\n",
      "the estimated relative tf for iter 15 is [-0.0028  0.0054 -0.0009  0.0492  0.0038 -0.0371  1.0131]\n",
      "the estimated relative tf for iter 16 is [-0.0027  0.014   0.001   0.07    0.014  -0.0847  1.0161]\n",
      "the estimated relative tf for iter 17 is [-0.0005 -0.0005 -0.      0.0566 -0.0001 -0.0099  1.0145]\n",
      "the estimated relative tf for iter 18 is [ 0.0026  0.0038 -0.0044  0.0583 -0.0258 -0.0265  1.0138]\n",
      "the estimated relative tf for iter 19 is [ 0.006   0.0028 -0.0093  0.0752 -0.049  -0.0224  1.0143]\n",
      "Function icp_once executed in 5.8048s\n",
      "\n",
      "==========estimation==========\n",
      "delta rotation:\n",
      "[[ 1.      0.0093  0.0028]\n",
      " [-0.0093  0.9999 -0.0061]\n",
      " [-0.0029  0.006   1.    ]]\n",
      "delta translation:\n",
      "[ 0.0752 -0.049  -0.0224]\n",
      "delta scale: 1.014\n",
      "\n",
      "======================================\n",
      "  =========   refine 5   ==========\n",
      "======================================\n",
      "the estimated relative tf for iter 0 is [0.0052 0.0084 0.0081 0.0148 0.012  0.0097 1.0002]\n",
      "the estimated relative tf for iter 1 is [0.005  0.0002 0.007  0.0117 0.0061 0.0473 1.0001]\n",
      "the estimated relative tf for iter 2 is [0.0019 0.0069 0.0092 0.0047 0.017  0.0035 1.0002]\n",
      "the estimated relative tf for iter 3 is [0.003  0.0056 0.0086 0.0019 0.0136 0.0137 1.0006]\n",
      "the estimated relative tf for iter 4 is [-0.0018 -0.0077  0.0079 -0.0017  0.0153  0.0637  1.0005]\n",
      "the estimated relative tf for iter 5 is [-0.0052  0.0004  0.0075 -0.0014  0.0148  0.0196  1.0007]\n",
      "the estimated relative tf for iter 6 is [-0.0085  0.0007  0.0054  0.0036  0.0134  0.0174  1.0019]\n",
      "the estimated relative tf for iter 7 is [-0.0107  0.0055  0.0067 -0.0086  0.0223 -0.0181  1.0008]\n",
      "the estimated relative tf for iter 8 is [-0.0074  0.0101  0.0041 -0.0044  0.0096 -0.0311  1.001 ]\n",
      "the estimated relative tf for iter 9 is [-0.0044  0.0083  0.0062 -0.014   0.0192 -0.0055  1.0013]\n",
      "the estimated relative tf for iter 10 is [-0.0042  0.0097  0.0044 -0.0098  0.0134 -0.0147  1.0019]\n",
      "the estimated relative tf for iter 11 is [-0.0057  0.0187 -0.0024  0.0003 -0.0124 -0.0632  1.0018]\n",
      "the estimated relative tf for iter 12 is [-0.0047  0.0167 -0.0052  0.0079 -0.0222 -0.0464  1.002 ]\n",
      "the estimated relative tf for iter 13 is [-0.0005  0.0064 -0.0113  0.0108 -0.0581  0.0142  0.9996]\n",
      "the estimated relative tf for iter 14 is [-0.0002 -0.0014 -0.0104  0.0054 -0.051   0.0432  0.9989]\n",
      "the estimated relative tf for iter 15 is [ 0.0026 -0.0014 -0.0046 -0.0008 -0.028   0.0409  0.9994]\n",
      "the estimated relative tf for iter 16 is [-0.0017  0.0084 -0.0035  0.005  -0.0177 -0.0204  1.0001]\n",
      "the estimated relative tf for iter 17 is [-0.0018  0.0047 -0.006   0.0098 -0.0267  0.007   1.0008]\n",
      "the estimated relative tf for iter 18 is [ 0.0007  0.0204 -0.006   0.0206 -0.0192 -0.0588  1.0031]\n",
      "the estimated relative tf for iter 19 is [-0.002   0.028  -0.0018  0.0156  0.0092 -0.1046  1.0047]\n",
      "Function icp_once executed in 5.6238s\n",
      "\n",
      "==========estimation==========\n",
      "delta rotation:\n",
      "[[ 0.9996  0.0018  0.028 ]\n",
      " [-0.0018  1.      0.002 ]\n",
      " [-0.028  -0.002   0.9996]]\n",
      "delta translation:\n",
      "[ 0.0156  0.0092 -0.1046]\n",
      "delta scale: 1.005\n",
      "\n",
      "======================================\n",
      "  =========   refine 6   ==========\n",
      "======================================\n",
      "the estimated relative tf for iter 0 is [0.008  0.0059 0.0104 0.0046 0.0126 0.021  0.9997]\n",
      "the estimated relative tf for iter 1 is [ 0.0024  0.0049  0.0077  0.0088 -0.0033 -0.0039  0.999 ]\n",
      "the estimated relative tf for iter 2 is [ 0.0025 -0.0092  0.0093 -0.0138 -0.0077  0.0599  0.9963]\n",
      "the estimated relative tf for iter 3 is [-0.0001 -0.0076  0.0048 -0.0033 -0.0264  0.0412  0.9964]\n",
      "the estimated relative tf for iter 4 is [ 0.0072 -0.0225  0.0083 -0.0285 -0.0173  0.1279  0.994 ]\n",
      "the estimated relative tf for iter 5 is [ 0.0049 -0.0173  0.0041 -0.0232 -0.0329  0.0963  0.994 ]\n",
      "the estimated relative tf for iter 6 is [ 0.0063 -0.0132  0.0058 -0.0161 -0.0272  0.0685  0.9958]\n",
      "the estimated relative tf for iter 7 is [ 0.0026 -0.0124  0.0038 -0.0155 -0.0263  0.0603  0.9964]\n",
      "the estimated relative tf for iter 8 is [ 0.0034 -0.0154  0.004  -0.01   -0.0261  0.0752  0.9973]\n",
      "the estimated relative tf for iter 9 is [ 0.0097 -0.0079  0.0025 -0.0068 -0.0302  0.0671  0.999 ]\n",
      "the estimated relative tf for iter 10 is [ 0.0099 -0.0016 -0.0005  0.0121 -0.039   0.0326  0.9998]\n",
      "the estimated relative tf for iter 11 is [ 0.0077 -0.0202 -0.0017 -0.0226 -0.0578  0.119   0.9951]\n",
      "the estimated relative tf for iter 12 is [ 0.0019 -0.0235 -0.0007 -0.0222 -0.0535  0.109   0.9949]\n",
      "the estimated relative tf for iter 13 is [-0.0009 -0.0259 -0.0024 -0.007  -0.0507  0.1033  0.9959]\n",
      "the estimated relative tf for iter 14 is [ 0.0011 -0.0241  0.0052 -0.0296 -0.0244  0.0932  0.9958]\n",
      "the estimated relative tf for iter 15 is [-0.0002 -0.0248  0.0045 -0.0199 -0.0193  0.0849  0.9975]\n",
      "the estimated relative tf for iter 16 is [-0.0117 -0.0345  0.0092 -0.0432  0.021   0.1028  0.9983]\n",
      "the estimated relative tf for iter 17 is [-0.003  -0.0393  0.0049 -0.0362 -0.0081  0.1477  0.9976]\n",
      "the estimated relative tf for iter 18 is [ 0.0013 -0.0463  0.0011 -0.0345 -0.0342  0.1978  0.9978]\n",
      "the estimated relative tf for iter 19 is [-0.0005 -0.0399  0.0004 -0.0264 -0.0363  0.1663  0.9977]\n",
      "Function icp_once executed in 5.5092s\n",
      "\n",
      "==========estimation==========\n",
      "delta rotation:\n",
      "[[ 0.9992 -0.0004 -0.0399]\n",
      " [ 0.0004  1.      0.0005]\n",
      " [ 0.0399 -0.0005  0.9992]]\n",
      "delta translation:\n",
      "[-0.0264 -0.0363  0.1663]\n",
      "delta scale: 0.998\n",
      "\n",
      "======================================\n",
      "  =========   refine 7   ==========\n",
      "======================================\n",
      "the estimated relative tf for iter 0 is [ 0.0085  0.0118  0.0103  0.0081  0.0185 -0.0022  1.0004]\n",
      "the estimated relative tf for iter 1 is [ 0.0072  0.0148  0.0041  0.0177  0.0073 -0.0178  1.0006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the estimated relative tf for iter 2 is [0.0091 0.0115 0.0058 0.0124 0.0199 0.0017 1.001 ]\n",
      "the estimated relative tf for iter 3 is [ 0.0031  0.0134  0.0051  0.0151  0.0216 -0.0248  1.001 ]\n",
      "the estimated relative tf for iter 4 is [-0.0018  0.0109  0.0018  0.0248  0.0095 -0.0358  1.0008]\n",
      "the estimated relative tf for iter 5 is [ 0.0009  0.0266 -0.0028  0.0532 -0.0092 -0.1022  1.0024]\n",
      "the estimated relative tf for iter 6 is [ 0.0051  0.0204 -0.0016  0.0397 -0.0056 -0.066   1.0017]\n",
      "the estimated relative tf for iter 7 is [-0.0008  0.0227 -0.      0.0307  0.0069 -0.0893  1.0016]\n",
      "the estimated relative tf for iter 8 is [-0.004   0.0188  0.003   0.0198  0.0254 -0.0773  1.0022]\n",
      "the estimated relative tf for iter 9 is [-0.0033  0.0166  0.0041  0.0153  0.0325 -0.0635  1.003 ]\n",
      "the estimated relative tf for iter 10 is [-0.0065  0.0206  0.0037  0.0134  0.0367 -0.0907  1.0032]\n",
      "the estimated relative tf for iter 11 is [-0.0025  0.0181  0.003   0.0135  0.0308 -0.0654  1.0032]\n",
      "the estimated relative tf for iter 12 is [-0.0059  0.023  -0.001   0.0191  0.0145 -0.1015  1.0033]\n",
      "the estimated relative tf for iter 13 is [ 0.0043  0.0164 -0.0035  0.0281 -0.0003 -0.0445  1.0014]\n",
      "the estimated relative tf for iter 14 is [-0.0029  0.0157 -0.0047  0.0311 -0.0022 -0.0543  1.0014]\n",
      "the estimated relative tf for iter 15 is [ 0.0073  0.0191 -0.0081  0.0357 -0.0185 -0.0419  1.0009]\n",
      "the estimated relative tf for iter 16 is [ 0.0069  0.0292 -0.0074  0.0406 -0.001  -0.0852  1.0027]\n",
      "the estimated relative tf for iter 17 is [ 0.0079  0.0275 -0.0064  0.0383 -0.0073 -0.096   1.0014]\n",
      "the estimated relative tf for iter 18 is [ 0.0041  0.0327  0.0044  0.01    0.0483 -0.1386  1.0006]\n",
      "the estimated relative tf for iter 19 is [ 0.0014  0.0199  0.0025  0.0073  0.0278 -0.0937  0.9983]\n",
      "Function icp_once executed in 5.1629s\n",
      "\n",
      "==========estimation==========\n",
      "delta rotation:\n",
      "[[ 0.9998 -0.0025  0.0199]\n",
      " [ 0.0025  1.     -0.0014]\n",
      " [-0.0199  0.0014  0.9998]]\n",
      "delta translation:\n",
      "[ 0.0073  0.0278 -0.0937]\n",
      "delta scale: 0.998\n",
      "\n",
      "======================================\n",
      "  =========   refine 8   ==========\n",
      "======================================\n",
      "the estimated relative tf for iter 0 is [ 0.0075  0.0113  0.0088  0.0164  0.0146 -0.0021  1.0012]\n",
      "the estimated relative tf for iter 1 is [ 0.0026  0.0106  0.0083  0.0117  0.0173 -0.0095  1.0013]\n",
      "the estimated relative tf for iter 2 is [0.0017 0.0019 0.0058 0.0015 0.0069 0.0378 0.9996]\n",
      "the estimated relative tf for iter 3 is [-0.0002  0.0083  0.0051  0.011   0.0084 -0.      1.0009]\n",
      "the estimated relative tf for iter 4 is [-0.0011  0.0088  0.0062  0.0171  0.0203 -0.009   1.002 ]\n",
      "the estimated relative tf for iter 5 is [ 0.0032 -0.0021  0.0071  0.001   0.0169  0.0531  1.0005]\n",
      "the estimated relative tf for iter 6 is [ 0.0092 -0.0062  0.0067  0.0026  0.0132  0.0847  1.0006]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     fix_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m tf_tangent, line_sets \u001b[38;5;241m=\u001b[39m \u001b[43micp_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_pc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_pc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_guess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpts_skip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43moutlier_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutlier_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mnum_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mfix_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfix_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# if \"true\" correspondence is given (this is an tutorial for education purpose), using a few iteration okay ..\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# 2. move the src to target and \u001b[39;00m\n\u001b[1;32m     82\u001b[0m est_rot3, est_trans3, est_scale \u001b[38;5;241m=\u001b[39m tf_tangent[:\u001b[38;5;241m3\u001b[39m], tf_tangent[\u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m6\u001b[39m], tf_tangent[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mtimer.<locals>.wrap_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      9\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 10\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     t2 \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m disp_timecost:\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36micp_once\u001b[0;34m(src, tgt, tf_init, skip, outlier_ratio, num_iters, fix_scale, verbose)\u001b[0m\n\u001b[1;32m     51\u001b[0m tgt_corres_idx, is_true_corres \\\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;241m=\u001b[39m probabilistic_false_corres_idx(pt_idx, num_pts\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, outlier_ratio\u001b[38;5;241m=\u001b[39moutlier_ratio) \u001b[38;5;66;03m# true \u001b[39;00m\n\u001b[1;32m     54\u001b[0m src_pt, tgt_pt \u001b[38;5;241m=\u001b[39m src[src_corres_idx, :], tgt[tgt_corres_idx, :]\n\u001b[1;32m     56\u001b[0m e, Je_rot, Je_trans, Je_scale \\\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_error_and_jacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_pt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_pt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf_init\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m#   ps. To understand the details of this nonlinear iterative update steps, see http://www.diag.uniroma1.it//~labrococo/tutorial_icra_2016/icra16_slam_tutorial_grisetti.pdf \u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m#       however, in the above slide's example, the jacobian was generated by hand as well as Euler angle space was used, not angle-axis.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fix_scale:\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mevaluate_error_and_jacobian\u001b[0;34m(src_pt, tag_pt, tf)\u001b[0m\n\u001b[1;32m     12\u001b[0m     model_evaluated \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m     13\u001b[0m         model\u001b[38;5;241m.\u001b[39msubs({rotvec: sf\u001b[38;5;241m.\u001b[39mV3(se3[:\u001b[38;5;241m3\u001b[39m]), \\\n\u001b[1;32m     14\u001b[0m                     transvec: sf\u001b[38;5;241m.\u001b[39mV3(se3[\u001b[38;5;241m3\u001b[39m:]), \\\n\u001b[1;32m     15\u001b[0m                     scale: sf\u001b[38;5;241m.\u001b[39mV1(s), \\\n\u001b[1;32m     16\u001b[0m                     p_src: sf\u001b[38;5;241m.\u001b[39mV3(src_pt), \\\n\u001b[1;32m     17\u001b[0m                     p_tgt: sf\u001b[38;5;241m.\u001b[39mV3(tag_pt)})\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_evaluated\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     20\u001b[0m error, Je_rot, Je_trans, Je_scale \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 21\u001b[0m     [inject_values(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [error_model, Je_rot_model, Je_trans_model, Je_scale_model]]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error, Je_rot, Je_trans, Je_scale\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m     model_evaluated \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m     13\u001b[0m         model\u001b[38;5;241m.\u001b[39msubs({rotvec: sf\u001b[38;5;241m.\u001b[39mV3(se3[:\u001b[38;5;241m3\u001b[39m]), \\\n\u001b[1;32m     14\u001b[0m                     transvec: sf\u001b[38;5;241m.\u001b[39mV3(se3[\u001b[38;5;241m3\u001b[39m:]), \\\n\u001b[1;32m     15\u001b[0m                     scale: sf\u001b[38;5;241m.\u001b[39mV1(s), \\\n\u001b[1;32m     16\u001b[0m                     p_src: sf\u001b[38;5;241m.\u001b[39mV3(src_pt), \\\n\u001b[1;32m     17\u001b[0m                     p_tgt: sf\u001b[38;5;241m.\u001b[39mV3(tag_pt)})\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_evaluated\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     20\u001b[0m error, Je_rot, Je_trans, Je_scale \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 21\u001b[0m     [\u001b[43minject_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [error_model, Je_rot_model, Je_trans_model, Je_scale_model]]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error, Je_rot, Je_trans, Je_scale\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mevaluate_error_and_jacobian.<locals>.inject_values\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minject_values\u001b[39m(model):\n\u001b[1;32m     12\u001b[0m     model_evaluated \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 13\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mrotvec\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mV3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mse3\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtransvec\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mV3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mse3\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mV1\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mp_src\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mV3\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_pt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mp_tgt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mV3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag_pt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_evaluated\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/symforce/ops/interfaces/storage.py:76\u001b[0m, in \u001b[0;36mStorage.subs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mSubstitute given values of each scalar element into a new instance.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# TODO(hayk): If this is slow, compute the subs dict once.\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_storage([sf\u001b[38;5;241m.\u001b[39mS(s)\u001b[38;5;241m.\u001b[39msubs(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_storage()])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/symforce/ops/interfaces/storage.py:76\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mSubstitute given values of each scalar element into a new instance.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# TODO(hayk): If this is slow, compute the subs dict once.\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_storage([\u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mS\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_storage()])\n",
      "File \u001b[0;32msymengine_wrapper.pyx:958\u001b[0m, in \u001b[0;36msymengine.lib.symengine_wrapper.Basic.subs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/symforce/internal/symbolic.py:643\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msymengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymengine_wrapper\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mwrapper\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=no-name-in-module\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     original_get_dict \u001b[38;5;241m=\u001b[39m wrapper\u001b[38;5;241m.\u001b[39mget_dict\n\u001b[0;32m--> 643\u001b[0m     wrapper\u001b[38;5;241m.\u001b[39mget_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: original_get_dict(\u001b[43m_get_subs_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sympy\u001b[38;5;241m.\u001b[39m__package__ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msympy\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    645\u001b[0m     original_subs \u001b[38;5;241m=\u001b[39m sympy\u001b[38;5;241m.\u001b[39mBasic\u001b[38;5;241m.\u001b[39msubs\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/symforce/internal/symbolic.py:633\u001b[0m, in \u001b[0;36m_get_subs_dict\u001b[0;34m(dont_flatten_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m         subs_pairs \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subs_pairs, T\u001b[38;5;241m.\u001b[39mSequence)\n\u001b[0;32m--> 633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flatten_storage_type_subs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubs_pairs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/symforce/internal/symbolic.py:587\u001b[0m, in \u001b[0;36m_flatten_storage_type_subs\u001b[0;34m(subs_pairs)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msymforce\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m python_util  \u001b[38;5;66;03m# pylint: disable=cyclic-import\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m subs_pairs:\n\u001b[0;32m--> 587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpython_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    588\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m python_util\u001b[38;5;241m.\u001b[39mscalar_like(value)\n\u001b[1;32m    589\u001b[0m         new_subs_dict[key] \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/symforce/python_util.py:201\u001b[0m, in \u001b[0;36mscalar_like\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# NOTE(brad): Each of these classes is automatically registered with ScalarLieGroupOps. (see\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# ops/__init__.py)\u001b[39;00m\n\u001b[1;32m    186\u001b[0m SCALAR_TYPES \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mfloat\u001b[39m,\n\u001b[1;32m    188\u001b[0m     np\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m     np\u001b[38;5;241m.\u001b[39mint64,\n\u001b[1;32m    198\u001b[0m )\n\u001b[0;32m--> 201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscalar_like\u001b[39m(a: T\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    Returns whether the element is scalar-like (an int, float, or sympy expression).\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    This method does not rely on the value of a, only the type.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m     a_type \u001b[38;5;241m=\u001b[39m get_type(a)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##########\n",
    "#  MAIN \n",
    "##########\n",
    "\n",
    "# At the very first status \n",
    "is_viz = 1\n",
    "if is_viz:\n",
    "    pcd0.paint_uniform_color([1, 0, 1])\n",
    "    pcd1.paint_uniform_color([0, 0, 1])\n",
    "    o3d.visualization.draw_geometries([pcd0, pcd1], window_name=\"initial status\")\n",
    "\n",
    "# Initial condition \n",
    "def gen_noisy_but_reliable_inital():\n",
    "    rot_init = R.from_euler('xyz', true_rot_diff_rpy, degrees=True).as_rotvec() + 0.05*np.random.rand(3)\n",
    "    trans_init = true_trans_diff + np.random.rand(3)*(0.1*scale_up)\n",
    "    scale_init = 0.7* true_scale_diff\n",
    "    \n",
    "    eps = 0.0001 # +eps means: because zero initial should be avoided (see the symbolic equation of Je_rot!)\n",
    "    initial_state_vector = np.hstack((rot_init, trans_init, scale_init)) + eps \n",
    "    return initial_state_vector\n",
    "\n",
    "def identity_inital():\n",
    "    eps = 0.01\n",
    "    return np.array([eps, eps, eps, eps, eps, eps, 1.0])\n",
    "    # because after the update, the registered_src is expected to be equal to the target \n",
    "    # thus, the translation and rotataion would be zero and the relative scale must be 1.0\n",
    "\n",
    "init_guess = gen_noisy_but_reliable_inital() \n",
    "# init_guess = gen_noisy_but_reliable_inital() \n",
    "    # at the very first step, a moderate (i.e., not-identity) initial value is required \n",
    "    # because the cost function is highly nonlinear\n",
    "    # ps. try yourself using init_guess = identity_inital() rather than gen_noisy_but_reliable_inital()\n",
    "    #  the convergence speed would be deteriorated. (test yourself!)\n",
    "print(f\"init_guess is {init_guess}\")\n",
    "\n",
    "# NOTE\n",
    "# The number of correspondences and their spatial distirbution would affect the results\n",
    "# for example, \n",
    "# in the below example, \n",
    "# for the dragon dataset, it will converge (when we use the robust loss) even under 50% outliers while using skip=20\n",
    "# however, for the bunny dataset, which has the more smaller number of points, would not converge when we use skip=20 (skip=1 is then okay. try yourself!)\n",
    "    # ps. for the production level code, you also adaptively conclude when num_iters should be stopped in the icp_once (e.g., by tracking the df or residuals)\n",
    "        # by doing so, you need to prevent the solution from divergent.   \n",
    "# therefore, the what I want to say is for parameter tuning, we should well understand your dataset's characteristics (e.g., density, spatial distribution, etc.)\n",
    "\n",
    "# the robust loss parameter is also important\n",
    "# for dragon, we will use \n",
    "\"\"\"\n",
    "    alpha = 0\n",
    "    delta = 0.1-0.2\n",
    "    scalar_information = 5-10\n",
    "    epsilon = 1.0e-6\n",
    "    \n",
    "    , and pts_skip = 20\n",
    "\"\"\"\n",
    "\n",
    "# ICP starts  \n",
    "max_iter = 25\n",
    "src_pc, tgt_pc = [np.array(pc.points) for pc in [pcd0, pcd1]]\n",
    "for _iter in range(max_iter):\n",
    "    print(f\"\\n======================================\")\n",
    "    print(f\"  =========   refine {_iter}   ==========\")\n",
    "    print(f\"======================================\")\n",
    "    # 1. optimize once \n",
    "    src_pc_before_updated = copy.deepcopy(src_pc)\n",
    "\n",
    "    outlier_ratio = 0.5 # test yourself up to 0.00 (no outlier) to 0.99\n",
    "    pts_skip = (10 + _iter) # for bunny (num points are small), use skip = 1 and for the dragon, use skip=20 is okay\n",
    "    num_iters = 20\n",
    "\n",
    "    if _iter < 0:\n",
    "        fix_scale=True \n",
    "    else:\n",
    "        fix_scale=False\n",
    "    tf_tangent, line_sets = icp_once(src_pc, tgt_pc, init_guess, skip=pts_skip, \\\n",
    "                                     outlier_ratio=outlier_ratio,\n",
    "                                     num_iters=num_iters,\n",
    "                                     fix_scale=fix_scale,\n",
    "                                     verbose=False) # if \"true\" correspondence is given (this is an tutorial for education purpose), using a few iteration okay ..\n",
    "\n",
    "    # 2. move the src to target and \n",
    "    est_rot3, est_trans3, est_scale = tf_tangent[:3], tf_tangent[3:6], tf_tangent[-1]\n",
    "    est_rotmat3x3 = rotmat.subs({rotvec: sf.V3(est_rot3)}).to_rotation_matrix().to_numpy()\n",
    "    src_pc_updated = est_scale*(est_rotmat3x3 @ src_pc.transpose()) + np.array([est_trans3]).transpose()\n",
    "    src_pc = src_pc_updated.transpose()\n",
    "    \n",
    "    init_guess = identity_inital()\n",
    "    # note: we explicitly update the source point cloud (i.e., registered), \n",
    "        # thus from the next step, we will use init_guess always equal to identity (toy example assumption)\n",
    "        # because, as already mentioned, after the update, the registered_src is expected to be equal to the target \n",
    "        # thus, the translation and rotataion would be zero and the relative scale must be 1.0\n",
    "        # in real world example, we need to use a domain knowledge to update the better initial (e.g., constant motion model, the prior knowledge of the object's metric scale, etc.)\n",
    "\n",
    "    # 3. re-correspondence\n",
    "    #  here, we can use the known true-correspondence because this is just a tutorial and affine transformation does not change the true correspondences \n",
    "    #   but in real world applications, kd-tree-like nearest neighbor search to find a newaly updated correspondences is required. \n",
    "\n",
    "    # 4. debug: Verify the result visually \n",
    "    if is_viz:\n",
    "        pcd0_Sim3_before_update = np2o3d(src_pc_before_updated)\n",
    "        pcd0_Sim3_before_update.paint_uniform_color([0.5, 0.5, 0.5])\n",
    "        \n",
    "        pcd0_Sim3_after_update = np2o3d(src_pc)\n",
    "        pcd0_Sim3_after_update.paint_uniform_color([25./255, 158./255, 243./255])\n",
    "        \n",
    "        pcd1.paint_uniform_color([0, 0, 1])\n",
    "        \n",
    "        line_sets[\"correct\"].paint_uniform_color([0, 0.737, 0.354])\n",
    "        if line_sets[\"false\"] is None:\n",
    "            line_sets[\"false\"] = copy.deepcopy(line_sets[\"correct\"])\n",
    "        else:\n",
    "            line_sets[\"false\"].paint_uniform_color([1.0, 0.0, 0.0])\n",
    "        \n",
    "        # draw before \n",
    "        o3d.visualization.draw_geometries([pcd0_Sim3_before_update, pcd1, \\\n",
    "                                           line_sets[\"correct\"], line_sets[\"false\"]], \\\n",
    "                                           window_name=f\"iteration {_iter} (gray: before update, blue: target)\")\n",
    "        \n",
    "        # draw after \n",
    "        o3d.visualization.draw_geometries([pcd0_Sim3_after_update, pcd1], \\\n",
    "                                           window_name=f\"iteration {_iter} (sky: after updated, blue: target)\")\n",
    "\n",
    "    # 5. if tf_tangent is smaller than a threshold, stop \n",
    "    print(\"\\n==========estimation==========\")\n",
    "    print(f\"delta rotation:\\n{est_rotmat3x3}\")\n",
    "    print(f\"delta translation:\\n{est_trans3}\")\n",
    "    print(f\"delta scale: {est_scale:.3f}\")\n",
    "    # TBA, e.g., if delta_translation < 0.01, break;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052b376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Future works \n",
    "\n",
    "# 1: \n",
    "# Here, the false residual and its Hessian is directly incorporated within the normal equation \n",
    "# we can say this deweighting method implictily handles the outliers. \n",
    "# The next step you can do is to \"explictly remove\" the false correspondences from the pairs \n",
    "# e.g., using RANSAC \n",
    "\n",
    "# 2:\n",
    "# using parallel implmentation, boost the above per-point iterations faster \n",
    "\n",
    "# 3:\n",
    "# using not a point-to-point L2 distance, using point-to-plane (using normal and dot product) loss\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
